{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35655e5-295e-4e4c-b5ad-51f76f019115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffef2bc-5046-4584-b4e6-7c7f5b2f362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtdp import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d777b00c-2d20-44c2-9949-c662a938e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(arch=\"resnet50\", pretrained=\"mtdp\", pool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8be1c97-08fa-4805-88b0-68d2c4f2b0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/user/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1eafab1a29940409975997bccb39e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "736589ee-3788-4375-8bfb-effc96d00327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PooledFeatureExtractor(\n",
       "  (features): NoHeadResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e76ae58f-7f4f-4e4a-9d77-07936631f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201b2811-c813-4cb9-8110-8a7ebf1a5c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================\n",
      "                                                      Kernel Shape  \\\n",
      "Layer                                                                \n",
      "0_features.Conv2d_conv1                              [3, 64, 7, 7]   \n",
      "1_features.BatchNorm2d_bn1                                    [64]   \n",
      "2_features.ReLU_relu                                             -   \n",
      "3_features.MaxPool2d_maxpool                                     -   \n",
      "4_features.layer1.0.Conv2d_conv1                    [64, 64, 1, 1]   \n",
      "5_features.layer1.0.BatchNorm2d_bn1                           [64]   \n",
      "6_features.layer1.0.ReLU_relu                                    -   \n",
      "7_features.layer1.0.Conv2d_conv2                    [64, 64, 3, 3]   \n",
      "8_features.layer1.0.BatchNorm2d_bn2                           [64]   \n",
      "9_features.layer1.0.ReLU_relu                                    -   \n",
      "10_features.layer1.0.Conv2d_conv3                  [64, 256, 1, 1]   \n",
      "11_features.layer1.0.BatchNorm2d_bn3                         [256]   \n",
      "12_features.layer1.0.downsample.Conv2d_0           [64, 256, 1, 1]   \n",
      "13_features.layer1.0.downsample.BatchNorm2d_1                [256]   \n",
      "14_features.layer1.0.ReLU_relu                                   -   \n",
      "15_features.layer1.1.Conv2d_conv1                  [256, 64, 1, 1]   \n",
      "16_features.layer1.1.BatchNorm2d_bn1                          [64]   \n",
      "17_features.layer1.1.ReLU_relu                                   -   \n",
      "18_features.layer1.1.Conv2d_conv2                   [64, 64, 3, 3]   \n",
      "19_features.layer1.1.BatchNorm2d_bn2                          [64]   \n",
      "20_features.layer1.1.ReLU_relu                                   -   \n",
      "21_features.layer1.1.Conv2d_conv3                  [64, 256, 1, 1]   \n",
      "22_features.layer1.1.BatchNorm2d_bn3                         [256]   \n",
      "23_features.layer1.1.ReLU_relu                                   -   \n",
      "24_features.layer1.2.Conv2d_conv1                  [256, 64, 1, 1]   \n",
      "25_features.layer1.2.BatchNorm2d_bn1                          [64]   \n",
      "26_features.layer1.2.ReLU_relu                                   -   \n",
      "27_features.layer1.2.Conv2d_conv2                   [64, 64, 3, 3]   \n",
      "28_features.layer1.2.BatchNorm2d_bn2                          [64]   \n",
      "29_features.layer1.2.ReLU_relu                                   -   \n",
      "30_features.layer1.2.Conv2d_conv3                  [64, 256, 1, 1]   \n",
      "31_features.layer1.2.BatchNorm2d_bn3                         [256]   \n",
      "32_features.layer1.2.ReLU_relu                                   -   \n",
      "33_features.layer2.0.Conv2d_conv1                 [256, 128, 1, 1]   \n",
      "34_features.layer2.0.BatchNorm2d_bn1                         [128]   \n",
      "35_features.layer2.0.ReLU_relu                                   -   \n",
      "36_features.layer2.0.Conv2d_conv2                 [128, 128, 3, 3]   \n",
      "37_features.layer2.0.BatchNorm2d_bn2                         [128]   \n",
      "38_features.layer2.0.ReLU_relu                                   -   \n",
      "39_features.layer2.0.Conv2d_conv3                 [128, 512, 1, 1]   \n",
      "40_features.layer2.0.BatchNorm2d_bn3                         [512]   \n",
      "41_features.layer2.0.downsample.Conv2d_0          [256, 512, 1, 1]   \n",
      "42_features.layer2.0.downsample.BatchNorm2d_1                [512]   \n",
      "43_features.layer2.0.ReLU_relu                                   -   \n",
      "44_features.layer2.1.Conv2d_conv1                 [512, 128, 1, 1]   \n",
      "45_features.layer2.1.BatchNorm2d_bn1                         [128]   \n",
      "46_features.layer2.1.ReLU_relu                                   -   \n",
      "47_features.layer2.1.Conv2d_conv2                 [128, 128, 3, 3]   \n",
      "48_features.layer2.1.BatchNorm2d_bn2                         [128]   \n",
      "49_features.layer2.1.ReLU_relu                                   -   \n",
      "50_features.layer2.1.Conv2d_conv3                 [128, 512, 1, 1]   \n",
      "51_features.layer2.1.BatchNorm2d_bn3                         [512]   \n",
      "52_features.layer2.1.ReLU_relu                                   -   \n",
      "53_features.layer2.2.Conv2d_conv1                 [512, 128, 1, 1]   \n",
      "54_features.layer2.2.BatchNorm2d_bn1                         [128]   \n",
      "55_features.layer2.2.ReLU_relu                                   -   \n",
      "56_features.layer2.2.Conv2d_conv2                 [128, 128, 3, 3]   \n",
      "57_features.layer2.2.BatchNorm2d_bn2                         [128]   \n",
      "58_features.layer2.2.ReLU_relu                                   -   \n",
      "59_features.layer2.2.Conv2d_conv3                 [128, 512, 1, 1]   \n",
      "60_features.layer2.2.BatchNorm2d_bn3                         [512]   \n",
      "61_features.layer2.2.ReLU_relu                                   -   \n",
      "62_features.layer2.3.Conv2d_conv1                 [512, 128, 1, 1]   \n",
      "63_features.layer2.3.BatchNorm2d_bn1                         [128]   \n",
      "64_features.layer2.3.ReLU_relu                                   -   \n",
      "65_features.layer2.3.Conv2d_conv2                 [128, 128, 3, 3]   \n",
      "66_features.layer2.3.BatchNorm2d_bn2                         [128]   \n",
      "67_features.layer2.3.ReLU_relu                                   -   \n",
      "68_features.layer2.3.Conv2d_conv3                 [128, 512, 1, 1]   \n",
      "69_features.layer2.3.BatchNorm2d_bn3                         [512]   \n",
      "70_features.layer2.3.ReLU_relu                                   -   \n",
      "71_features.layer3.0.Conv2d_conv1                 [512, 256, 1, 1]   \n",
      "72_features.layer3.0.BatchNorm2d_bn1                         [256]   \n",
      "73_features.layer3.0.ReLU_relu                                   -   \n",
      "74_features.layer3.0.Conv2d_conv2                 [256, 256, 3, 3]   \n",
      "75_features.layer3.0.BatchNorm2d_bn2                         [256]   \n",
      "76_features.layer3.0.ReLU_relu                                   -   \n",
      "77_features.layer3.0.Conv2d_conv3                [256, 1024, 1, 1]   \n",
      "78_features.layer3.0.BatchNorm2d_bn3                        [1024]   \n",
      "79_features.layer3.0.downsample.Conv2d_0         [512, 1024, 1, 1]   \n",
      "80_features.layer3.0.downsample.BatchNorm2d_1               [1024]   \n",
      "81_features.layer3.0.ReLU_relu                                   -   \n",
      "82_features.layer3.1.Conv2d_conv1                [1024, 256, 1, 1]   \n",
      "83_features.layer3.1.BatchNorm2d_bn1                         [256]   \n",
      "84_features.layer3.1.ReLU_relu                                   -   \n",
      "85_features.layer3.1.Conv2d_conv2                 [256, 256, 3, 3]   \n",
      "86_features.layer3.1.BatchNorm2d_bn2                         [256]   \n",
      "87_features.layer3.1.ReLU_relu                                   -   \n",
      "88_features.layer3.1.Conv2d_conv3                [256, 1024, 1, 1]   \n",
      "89_features.layer3.1.BatchNorm2d_bn3                        [1024]   \n",
      "90_features.layer3.1.ReLU_relu                                   -   \n",
      "91_features.layer3.2.Conv2d_conv1                [1024, 256, 1, 1]   \n",
      "92_features.layer3.2.BatchNorm2d_bn1                         [256]   \n",
      "93_features.layer3.2.ReLU_relu                                   -   \n",
      "94_features.layer3.2.Conv2d_conv2                 [256, 256, 3, 3]   \n",
      "95_features.layer3.2.BatchNorm2d_bn2                         [256]   \n",
      "96_features.layer3.2.ReLU_relu                                   -   \n",
      "97_features.layer3.2.Conv2d_conv3                [256, 1024, 1, 1]   \n",
      "98_features.layer3.2.BatchNorm2d_bn3                        [1024]   \n",
      "99_features.layer3.2.ReLU_relu                                   -   \n",
      "100_features.layer3.3.Conv2d_conv1               [1024, 256, 1, 1]   \n",
      "101_features.layer3.3.BatchNorm2d_bn1                        [256]   \n",
      "102_features.layer3.3.ReLU_relu                                  -   \n",
      "103_features.layer3.3.Conv2d_conv2                [256, 256, 3, 3]   \n",
      "104_features.layer3.3.BatchNorm2d_bn2                        [256]   \n",
      "105_features.layer3.3.ReLU_relu                                  -   \n",
      "106_features.layer3.3.Conv2d_conv3               [256, 1024, 1, 1]   \n",
      "107_features.layer3.3.BatchNorm2d_bn3                       [1024]   \n",
      "108_features.layer3.3.ReLU_relu                                  -   \n",
      "109_features.layer3.4.Conv2d_conv1               [1024, 256, 1, 1]   \n",
      "110_features.layer3.4.BatchNorm2d_bn1                        [256]   \n",
      "111_features.layer3.4.ReLU_relu                                  -   \n",
      "112_features.layer3.4.Conv2d_conv2                [256, 256, 3, 3]   \n",
      "113_features.layer3.4.BatchNorm2d_bn2                        [256]   \n",
      "114_features.layer3.4.ReLU_relu                                  -   \n",
      "115_features.layer3.4.Conv2d_conv3               [256, 1024, 1, 1]   \n",
      "116_features.layer3.4.BatchNorm2d_bn3                       [1024]   \n",
      "117_features.layer3.4.ReLU_relu                                  -   \n",
      "118_features.layer3.5.Conv2d_conv1               [1024, 256, 1, 1]   \n",
      "119_features.layer3.5.BatchNorm2d_bn1                        [256]   \n",
      "120_features.layer3.5.ReLU_relu                                  -   \n",
      "121_features.layer3.5.Conv2d_conv2                [256, 256, 3, 3]   \n",
      "122_features.layer3.5.BatchNorm2d_bn2                        [256]   \n",
      "123_features.layer3.5.ReLU_relu                                  -   \n",
      "124_features.layer3.5.Conv2d_conv3               [256, 1024, 1, 1]   \n",
      "125_features.layer3.5.BatchNorm2d_bn3                       [1024]   \n",
      "126_features.layer3.5.ReLU_relu                                  -   \n",
      "127_features.layer4.0.Conv2d_conv1               [1024, 512, 1, 1]   \n",
      "128_features.layer4.0.BatchNorm2d_bn1                        [512]   \n",
      "129_features.layer4.0.ReLU_relu                                  -   \n",
      "130_features.layer4.0.Conv2d_conv2                [512, 512, 3, 3]   \n",
      "131_features.layer4.0.BatchNorm2d_bn2                        [512]   \n",
      "132_features.layer4.0.ReLU_relu                                  -   \n",
      "133_features.layer4.0.Conv2d_conv3               [512, 2048, 1, 1]   \n",
      "134_features.layer4.0.BatchNorm2d_bn3                       [2048]   \n",
      "135_features.layer4.0.downsample.Conv2d_0       [1024, 2048, 1, 1]   \n",
      "136_features.layer4.0.downsample.BatchNorm2d_1              [2048]   \n",
      "137_features.layer4.0.ReLU_relu                                  -   \n",
      "138_features.layer4.1.Conv2d_conv1               [2048, 512, 1, 1]   \n",
      "139_features.layer4.1.BatchNorm2d_bn1                        [512]   \n",
      "140_features.layer4.1.ReLU_relu                                  -   \n",
      "141_features.layer4.1.Conv2d_conv2                [512, 512, 3, 3]   \n",
      "142_features.layer4.1.BatchNorm2d_bn2                        [512]   \n",
      "143_features.layer4.1.ReLU_relu                                  -   \n",
      "144_features.layer4.1.Conv2d_conv3               [512, 2048, 1, 1]   \n",
      "145_features.layer4.1.BatchNorm2d_bn3                       [2048]   \n",
      "146_features.layer4.1.ReLU_relu                                  -   \n",
      "147_features.layer4.2.Conv2d_conv1               [2048, 512, 1, 1]   \n",
      "148_features.layer4.2.BatchNorm2d_bn1                        [512]   \n",
      "149_features.layer4.2.ReLU_relu                                  -   \n",
      "150_features.layer4.2.Conv2d_conv2                [512, 512, 3, 3]   \n",
      "151_features.layer4.2.BatchNorm2d_bn2                        [512]   \n",
      "152_features.layer4.2.ReLU_relu                                  -   \n",
      "153_features.layer4.2.Conv2d_conv3               [512, 2048, 1, 1]   \n",
      "154_features.layer4.2.BatchNorm2d_bn3                       [2048]   \n",
      "155_features.layer4.2.ReLU_relu                                  -   \n",
      "156_pool                                                         -   \n",
      "\n",
      "                                                      Output Shape     Params  \\\n",
      "Layer                                                                           \n",
      "0_features.Conv2d_conv1                          [1, 64, 256, 256]     9.408k   \n",
      "1_features.BatchNorm2d_bn1                       [1, 64, 256, 256]      128.0   \n",
      "2_features.ReLU_relu                             [1, 64, 256, 256]          -   \n",
      "3_features.MaxPool2d_maxpool                     [1, 64, 128, 128]          -   \n",
      "4_features.layer1.0.Conv2d_conv1                 [1, 64, 128, 128]     4.096k   \n",
      "5_features.layer1.0.BatchNorm2d_bn1              [1, 64, 128, 128]      128.0   \n",
      "6_features.layer1.0.ReLU_relu                    [1, 64, 128, 128]          -   \n",
      "7_features.layer1.0.Conv2d_conv2                 [1, 64, 128, 128]    36.864k   \n",
      "8_features.layer1.0.BatchNorm2d_bn2              [1, 64, 128, 128]      128.0   \n",
      "9_features.layer1.0.ReLU_relu                    [1, 64, 128, 128]          -   \n",
      "10_features.layer1.0.Conv2d_conv3               [1, 256, 128, 128]    16.384k   \n",
      "11_features.layer1.0.BatchNorm2d_bn3            [1, 256, 128, 128]      512.0   \n",
      "12_features.layer1.0.downsample.Conv2d_0        [1, 256, 128, 128]    16.384k   \n",
      "13_features.layer1.0.downsample.BatchNorm2d_1   [1, 256, 128, 128]      512.0   \n",
      "14_features.layer1.0.ReLU_relu                  [1, 256, 128, 128]          -   \n",
      "15_features.layer1.1.Conv2d_conv1                [1, 64, 128, 128]    16.384k   \n",
      "16_features.layer1.1.BatchNorm2d_bn1             [1, 64, 128, 128]      128.0   \n",
      "17_features.layer1.1.ReLU_relu                   [1, 64, 128, 128]          -   \n",
      "18_features.layer1.1.Conv2d_conv2                [1, 64, 128, 128]    36.864k   \n",
      "19_features.layer1.1.BatchNorm2d_bn2             [1, 64, 128, 128]      128.0   \n",
      "20_features.layer1.1.ReLU_relu                   [1, 64, 128, 128]          -   \n",
      "21_features.layer1.1.Conv2d_conv3               [1, 256, 128, 128]    16.384k   \n",
      "22_features.layer1.1.BatchNorm2d_bn3            [1, 256, 128, 128]      512.0   \n",
      "23_features.layer1.1.ReLU_relu                  [1, 256, 128, 128]          -   \n",
      "24_features.layer1.2.Conv2d_conv1                [1, 64, 128, 128]    16.384k   \n",
      "25_features.layer1.2.BatchNorm2d_bn1             [1, 64, 128, 128]      128.0   \n",
      "26_features.layer1.2.ReLU_relu                   [1, 64, 128, 128]          -   \n",
      "27_features.layer1.2.Conv2d_conv2                [1, 64, 128, 128]    36.864k   \n",
      "28_features.layer1.2.BatchNorm2d_bn2             [1, 64, 128, 128]      128.0   \n",
      "29_features.layer1.2.ReLU_relu                   [1, 64, 128, 128]          -   \n",
      "30_features.layer1.2.Conv2d_conv3               [1, 256, 128, 128]    16.384k   \n",
      "31_features.layer1.2.BatchNorm2d_bn3            [1, 256, 128, 128]      512.0   \n",
      "32_features.layer1.2.ReLU_relu                  [1, 256, 128, 128]          -   \n",
      "33_features.layer2.0.Conv2d_conv1               [1, 128, 128, 128]    32.768k   \n",
      "34_features.layer2.0.BatchNorm2d_bn1            [1, 128, 128, 128]      256.0   \n",
      "35_features.layer2.0.ReLU_relu                  [1, 128, 128, 128]          -   \n",
      "36_features.layer2.0.Conv2d_conv2                 [1, 128, 64, 64]   147.456k   \n",
      "37_features.layer2.0.BatchNorm2d_bn2              [1, 128, 64, 64]      256.0   \n",
      "38_features.layer2.0.ReLU_relu                    [1, 128, 64, 64]          -   \n",
      "39_features.layer2.0.Conv2d_conv3                 [1, 512, 64, 64]    65.536k   \n",
      "40_features.layer2.0.BatchNorm2d_bn3              [1, 512, 64, 64]     1.024k   \n",
      "41_features.layer2.0.downsample.Conv2d_0          [1, 512, 64, 64]   131.072k   \n",
      "42_features.layer2.0.downsample.BatchNorm2d_1     [1, 512, 64, 64]     1.024k   \n",
      "43_features.layer2.0.ReLU_relu                    [1, 512, 64, 64]          -   \n",
      "44_features.layer2.1.Conv2d_conv1                 [1, 128, 64, 64]    65.536k   \n",
      "45_features.layer2.1.BatchNorm2d_bn1              [1, 128, 64, 64]      256.0   \n",
      "46_features.layer2.1.ReLU_relu                    [1, 128, 64, 64]          -   \n",
      "47_features.layer2.1.Conv2d_conv2                 [1, 128, 64, 64]   147.456k   \n",
      "48_features.layer2.1.BatchNorm2d_bn2              [1, 128, 64, 64]      256.0   \n",
      "49_features.layer2.1.ReLU_relu                    [1, 128, 64, 64]          -   \n",
      "50_features.layer2.1.Conv2d_conv3                 [1, 512, 64, 64]    65.536k   \n",
      "51_features.layer2.1.BatchNorm2d_bn3              [1, 512, 64, 64]     1.024k   \n",
      "52_features.layer2.1.ReLU_relu                    [1, 512, 64, 64]          -   \n",
      "53_features.layer2.2.Conv2d_conv1                 [1, 128, 64, 64]    65.536k   \n",
      "54_features.layer2.2.BatchNorm2d_bn1              [1, 128, 64, 64]      256.0   \n",
      "55_features.layer2.2.ReLU_relu                    [1, 128, 64, 64]          -   \n",
      "56_features.layer2.2.Conv2d_conv2                 [1, 128, 64, 64]   147.456k   \n",
      "57_features.layer2.2.BatchNorm2d_bn2              [1, 128, 64, 64]      256.0   \n",
      "58_features.layer2.2.ReLU_relu                    [1, 128, 64, 64]          -   \n",
      "59_features.layer2.2.Conv2d_conv3                 [1, 512, 64, 64]    65.536k   \n",
      "60_features.layer2.2.BatchNorm2d_bn3              [1, 512, 64, 64]     1.024k   \n",
      "61_features.layer2.2.ReLU_relu                    [1, 512, 64, 64]          -   \n",
      "62_features.layer2.3.Conv2d_conv1                 [1, 128, 64, 64]    65.536k   \n",
      "63_features.layer2.3.BatchNorm2d_bn1              [1, 128, 64, 64]      256.0   \n",
      "64_features.layer2.3.ReLU_relu                    [1, 128, 64, 64]          -   \n",
      "65_features.layer2.3.Conv2d_conv2                 [1, 128, 64, 64]   147.456k   \n",
      "66_features.layer2.3.BatchNorm2d_bn2              [1, 128, 64, 64]      256.0   \n",
      "67_features.layer2.3.ReLU_relu                    [1, 128, 64, 64]          -   \n",
      "68_features.layer2.3.Conv2d_conv3                 [1, 512, 64, 64]    65.536k   \n",
      "69_features.layer2.3.BatchNorm2d_bn3              [1, 512, 64, 64]     1.024k   \n",
      "70_features.layer2.3.ReLU_relu                    [1, 512, 64, 64]          -   \n",
      "71_features.layer3.0.Conv2d_conv1                 [1, 256, 64, 64]   131.072k   \n",
      "72_features.layer3.0.BatchNorm2d_bn1              [1, 256, 64, 64]      512.0   \n",
      "73_features.layer3.0.ReLU_relu                    [1, 256, 64, 64]          -   \n",
      "74_features.layer3.0.Conv2d_conv2                 [1, 256, 32, 32]   589.824k   \n",
      "75_features.layer3.0.BatchNorm2d_bn2              [1, 256, 32, 32]      512.0   \n",
      "76_features.layer3.0.ReLU_relu                    [1, 256, 32, 32]          -   \n",
      "77_features.layer3.0.Conv2d_conv3                [1, 1024, 32, 32]   262.144k   \n",
      "78_features.layer3.0.BatchNorm2d_bn3             [1, 1024, 32, 32]     2.048k   \n",
      "79_features.layer3.0.downsample.Conv2d_0         [1, 1024, 32, 32]   524.288k   \n",
      "80_features.layer3.0.downsample.BatchNorm2d_1    [1, 1024, 32, 32]     2.048k   \n",
      "81_features.layer3.0.ReLU_relu                   [1, 1024, 32, 32]          -   \n",
      "82_features.layer3.1.Conv2d_conv1                 [1, 256, 32, 32]   262.144k   \n",
      "83_features.layer3.1.BatchNorm2d_bn1              [1, 256, 32, 32]      512.0   \n",
      "84_features.layer3.1.ReLU_relu                    [1, 256, 32, 32]          -   \n",
      "85_features.layer3.1.Conv2d_conv2                 [1, 256, 32, 32]   589.824k   \n",
      "86_features.layer3.1.BatchNorm2d_bn2              [1, 256, 32, 32]      512.0   \n",
      "87_features.layer3.1.ReLU_relu                    [1, 256, 32, 32]          -   \n",
      "88_features.layer3.1.Conv2d_conv3                [1, 1024, 32, 32]   262.144k   \n",
      "89_features.layer3.1.BatchNorm2d_bn3             [1, 1024, 32, 32]     2.048k   \n",
      "90_features.layer3.1.ReLU_relu                   [1, 1024, 32, 32]          -   \n",
      "91_features.layer3.2.Conv2d_conv1                 [1, 256, 32, 32]   262.144k   \n",
      "92_features.layer3.2.BatchNorm2d_bn1              [1, 256, 32, 32]      512.0   \n",
      "93_features.layer3.2.ReLU_relu                    [1, 256, 32, 32]          -   \n",
      "94_features.layer3.2.Conv2d_conv2                 [1, 256, 32, 32]   589.824k   \n",
      "95_features.layer3.2.BatchNorm2d_bn2              [1, 256, 32, 32]      512.0   \n",
      "96_features.layer3.2.ReLU_relu                    [1, 256, 32, 32]          -   \n",
      "97_features.layer3.2.Conv2d_conv3                [1, 1024, 32, 32]   262.144k   \n",
      "98_features.layer3.2.BatchNorm2d_bn3             [1, 1024, 32, 32]     2.048k   \n",
      "99_features.layer3.2.ReLU_relu                   [1, 1024, 32, 32]          -   \n",
      "100_features.layer3.3.Conv2d_conv1                [1, 256, 32, 32]   262.144k   \n",
      "101_features.layer3.3.BatchNorm2d_bn1             [1, 256, 32, 32]      512.0   \n",
      "102_features.layer3.3.ReLU_relu                   [1, 256, 32, 32]          -   \n",
      "103_features.layer3.3.Conv2d_conv2                [1, 256, 32, 32]   589.824k   \n",
      "104_features.layer3.3.BatchNorm2d_bn2             [1, 256, 32, 32]      512.0   \n",
      "105_features.layer3.3.ReLU_relu                   [1, 256, 32, 32]          -   \n",
      "106_features.layer3.3.Conv2d_conv3               [1, 1024, 32, 32]   262.144k   \n",
      "107_features.layer3.3.BatchNorm2d_bn3            [1, 1024, 32, 32]     2.048k   \n",
      "108_features.layer3.3.ReLU_relu                  [1, 1024, 32, 32]          -   \n",
      "109_features.layer3.4.Conv2d_conv1                [1, 256, 32, 32]   262.144k   \n",
      "110_features.layer3.4.BatchNorm2d_bn1             [1, 256, 32, 32]      512.0   \n",
      "111_features.layer3.4.ReLU_relu                   [1, 256, 32, 32]          -   \n",
      "112_features.layer3.4.Conv2d_conv2                [1, 256, 32, 32]   589.824k   \n",
      "113_features.layer3.4.BatchNorm2d_bn2             [1, 256, 32, 32]      512.0   \n",
      "114_features.layer3.4.ReLU_relu                   [1, 256, 32, 32]          -   \n",
      "115_features.layer3.4.Conv2d_conv3               [1, 1024, 32, 32]   262.144k   \n",
      "116_features.layer3.4.BatchNorm2d_bn3            [1, 1024, 32, 32]     2.048k   \n",
      "117_features.layer3.4.ReLU_relu                  [1, 1024, 32, 32]          -   \n",
      "118_features.layer3.5.Conv2d_conv1                [1, 256, 32, 32]   262.144k   \n",
      "119_features.layer3.5.BatchNorm2d_bn1             [1, 256, 32, 32]      512.0   \n",
      "120_features.layer3.5.ReLU_relu                   [1, 256, 32, 32]          -   \n",
      "121_features.layer3.5.Conv2d_conv2                [1, 256, 32, 32]   589.824k   \n",
      "122_features.layer3.5.BatchNorm2d_bn2             [1, 256, 32, 32]      512.0   \n",
      "123_features.layer3.5.ReLU_relu                   [1, 256, 32, 32]          -   \n",
      "124_features.layer3.5.Conv2d_conv3               [1, 1024, 32, 32]   262.144k   \n",
      "125_features.layer3.5.BatchNorm2d_bn3            [1, 1024, 32, 32]     2.048k   \n",
      "126_features.layer3.5.ReLU_relu                  [1, 1024, 32, 32]          -   \n",
      "127_features.layer4.0.Conv2d_conv1                [1, 512, 32, 32]   524.288k   \n",
      "128_features.layer4.0.BatchNorm2d_bn1             [1, 512, 32, 32]     1.024k   \n",
      "129_features.layer4.0.ReLU_relu                   [1, 512, 32, 32]          -   \n",
      "130_features.layer4.0.Conv2d_conv2                [1, 512, 16, 16]  2.359296M   \n",
      "131_features.layer4.0.BatchNorm2d_bn2             [1, 512, 16, 16]     1.024k   \n",
      "132_features.layer4.0.ReLU_relu                   [1, 512, 16, 16]          -   \n",
      "133_features.layer4.0.Conv2d_conv3               [1, 2048, 16, 16]  1.048576M   \n",
      "134_features.layer4.0.BatchNorm2d_bn3            [1, 2048, 16, 16]     4.096k   \n",
      "135_features.layer4.0.downsample.Conv2d_0        [1, 2048, 16, 16]  2.097152M   \n",
      "136_features.layer4.0.downsample.BatchNorm2d_1   [1, 2048, 16, 16]     4.096k   \n",
      "137_features.layer4.0.ReLU_relu                  [1, 2048, 16, 16]          -   \n",
      "138_features.layer4.1.Conv2d_conv1                [1, 512, 16, 16]  1.048576M   \n",
      "139_features.layer4.1.BatchNorm2d_bn1             [1, 512, 16, 16]     1.024k   \n",
      "140_features.layer4.1.ReLU_relu                   [1, 512, 16, 16]          -   \n",
      "141_features.layer4.1.Conv2d_conv2                [1, 512, 16, 16]  2.359296M   \n",
      "142_features.layer4.1.BatchNorm2d_bn2             [1, 512, 16, 16]     1.024k   \n",
      "143_features.layer4.1.ReLU_relu                   [1, 512, 16, 16]          -   \n",
      "144_features.layer4.1.Conv2d_conv3               [1, 2048, 16, 16]  1.048576M   \n",
      "145_features.layer4.1.BatchNorm2d_bn3            [1, 2048, 16, 16]     4.096k   \n",
      "146_features.layer4.1.ReLU_relu                  [1, 2048, 16, 16]          -   \n",
      "147_features.layer4.2.Conv2d_conv1                [1, 512, 16, 16]  1.048576M   \n",
      "148_features.layer4.2.BatchNorm2d_bn1             [1, 512, 16, 16]     1.024k   \n",
      "149_features.layer4.2.ReLU_relu                   [1, 512, 16, 16]          -   \n",
      "150_features.layer4.2.Conv2d_conv2                [1, 512, 16, 16]  2.359296M   \n",
      "151_features.layer4.2.BatchNorm2d_bn2             [1, 512, 16, 16]     1.024k   \n",
      "152_features.layer4.2.ReLU_relu                   [1, 512, 16, 16]          -   \n",
      "153_features.layer4.2.Conv2d_conv3               [1, 2048, 16, 16]  1.048576M   \n",
      "154_features.layer4.2.BatchNorm2d_bn3            [1, 2048, 16, 16]     4.096k   \n",
      "155_features.layer4.2.ReLU_relu                  [1, 2048, 16, 16]          -   \n",
      "156_pool                                           [1, 2048, 1, 1]          -   \n",
      "\n",
      "                                                  Mult-Adds  \n",
      "Layer                                                        \n",
      "0_features.Conv2d_conv1                         616.562688M  \n",
      "1_features.BatchNorm2d_bn1                             64.0  \n",
      "2_features.ReLU_relu                                      -  \n",
      "3_features.MaxPool2d_maxpool                              -  \n",
      "4_features.layer1.0.Conv2d_conv1                 67.108864M  \n",
      "5_features.layer1.0.BatchNorm2d_bn1                    64.0  \n",
      "6_features.layer1.0.ReLU_relu                             -  \n",
      "7_features.layer1.0.Conv2d_conv2                603.979776M  \n",
      "8_features.layer1.0.BatchNorm2d_bn2                    64.0  \n",
      "9_features.layer1.0.ReLU_relu                             -  \n",
      "10_features.layer1.0.Conv2d_conv3               268.435456M  \n",
      "11_features.layer1.0.BatchNorm2d_bn3                  256.0  \n",
      "12_features.layer1.0.downsample.Conv2d_0        268.435456M  \n",
      "13_features.layer1.0.downsample.BatchNorm2d_1         256.0  \n",
      "14_features.layer1.0.ReLU_relu                            -  \n",
      "15_features.layer1.1.Conv2d_conv1               268.435456M  \n",
      "16_features.layer1.1.BatchNorm2d_bn1                   64.0  \n",
      "17_features.layer1.1.ReLU_relu                            -  \n",
      "18_features.layer1.1.Conv2d_conv2               603.979776M  \n",
      "19_features.layer1.1.BatchNorm2d_bn2                   64.0  \n",
      "20_features.layer1.1.ReLU_relu                            -  \n",
      "21_features.layer1.1.Conv2d_conv3               268.435456M  \n",
      "22_features.layer1.1.BatchNorm2d_bn3                  256.0  \n",
      "23_features.layer1.1.ReLU_relu                            -  \n",
      "24_features.layer1.2.Conv2d_conv1               268.435456M  \n",
      "25_features.layer1.2.BatchNorm2d_bn1                   64.0  \n",
      "26_features.layer1.2.ReLU_relu                            -  \n",
      "27_features.layer1.2.Conv2d_conv2               603.979776M  \n",
      "28_features.layer1.2.BatchNorm2d_bn2                   64.0  \n",
      "29_features.layer1.2.ReLU_relu                            -  \n",
      "30_features.layer1.2.Conv2d_conv3               268.435456M  \n",
      "31_features.layer1.2.BatchNorm2d_bn3                  256.0  \n",
      "32_features.layer1.2.ReLU_relu                            -  \n",
      "33_features.layer2.0.Conv2d_conv1               536.870912M  \n",
      "34_features.layer2.0.BatchNorm2d_bn1                  128.0  \n",
      "35_features.layer2.0.ReLU_relu                            -  \n",
      "36_features.layer2.0.Conv2d_conv2               603.979776M  \n",
      "37_features.layer2.0.BatchNorm2d_bn2                  128.0  \n",
      "38_features.layer2.0.ReLU_relu                            -  \n",
      "39_features.layer2.0.Conv2d_conv3               268.435456M  \n",
      "40_features.layer2.0.BatchNorm2d_bn3                  512.0  \n",
      "41_features.layer2.0.downsample.Conv2d_0        536.870912M  \n",
      "42_features.layer2.0.downsample.BatchNorm2d_1         512.0  \n",
      "43_features.layer2.0.ReLU_relu                            -  \n",
      "44_features.layer2.1.Conv2d_conv1               268.435456M  \n",
      "45_features.layer2.1.BatchNorm2d_bn1                  128.0  \n",
      "46_features.layer2.1.ReLU_relu                            -  \n",
      "47_features.layer2.1.Conv2d_conv2               603.979776M  \n",
      "48_features.layer2.1.BatchNorm2d_bn2                  128.0  \n",
      "49_features.layer2.1.ReLU_relu                            -  \n",
      "50_features.layer2.1.Conv2d_conv3               268.435456M  \n",
      "51_features.layer2.1.BatchNorm2d_bn3                  512.0  \n",
      "52_features.layer2.1.ReLU_relu                            -  \n",
      "53_features.layer2.2.Conv2d_conv1               268.435456M  \n",
      "54_features.layer2.2.BatchNorm2d_bn1                  128.0  \n",
      "55_features.layer2.2.ReLU_relu                            -  \n",
      "56_features.layer2.2.Conv2d_conv2               603.979776M  \n",
      "57_features.layer2.2.BatchNorm2d_bn2                  128.0  \n",
      "58_features.layer2.2.ReLU_relu                            -  \n",
      "59_features.layer2.2.Conv2d_conv3               268.435456M  \n",
      "60_features.layer2.2.BatchNorm2d_bn3                  512.0  \n",
      "61_features.layer2.2.ReLU_relu                            -  \n",
      "62_features.layer2.3.Conv2d_conv1               268.435456M  \n",
      "63_features.layer2.3.BatchNorm2d_bn1                  128.0  \n",
      "64_features.layer2.3.ReLU_relu                            -  \n",
      "65_features.layer2.3.Conv2d_conv2               603.979776M  \n",
      "66_features.layer2.3.BatchNorm2d_bn2                  128.0  \n",
      "67_features.layer2.3.ReLU_relu                            -  \n",
      "68_features.layer2.3.Conv2d_conv3               268.435456M  \n",
      "69_features.layer2.3.BatchNorm2d_bn3                  512.0  \n",
      "70_features.layer2.3.ReLU_relu                            -  \n",
      "71_features.layer3.0.Conv2d_conv1               536.870912M  \n",
      "72_features.layer3.0.BatchNorm2d_bn1                  256.0  \n",
      "73_features.layer3.0.ReLU_relu                            -  \n",
      "74_features.layer3.0.Conv2d_conv2               603.979776M  \n",
      "75_features.layer3.0.BatchNorm2d_bn2                  256.0  \n",
      "76_features.layer3.0.ReLU_relu                            -  \n",
      "77_features.layer3.0.Conv2d_conv3               268.435456M  \n",
      "78_features.layer3.0.BatchNorm2d_bn3                 1.024k  \n",
      "79_features.layer3.0.downsample.Conv2d_0        536.870912M  \n",
      "80_features.layer3.0.downsample.BatchNorm2d_1        1.024k  \n",
      "81_features.layer3.0.ReLU_relu                            -  \n",
      "82_features.layer3.1.Conv2d_conv1               268.435456M  \n",
      "83_features.layer3.1.BatchNorm2d_bn1                  256.0  \n",
      "84_features.layer3.1.ReLU_relu                            -  \n",
      "85_features.layer3.1.Conv2d_conv2               603.979776M  \n",
      "86_features.layer3.1.BatchNorm2d_bn2                  256.0  \n",
      "87_features.layer3.1.ReLU_relu                            -  \n",
      "88_features.layer3.1.Conv2d_conv3               268.435456M  \n",
      "89_features.layer3.1.BatchNorm2d_bn3                 1.024k  \n",
      "90_features.layer3.1.ReLU_relu                            -  \n",
      "91_features.layer3.2.Conv2d_conv1               268.435456M  \n",
      "92_features.layer3.2.BatchNorm2d_bn1                  256.0  \n",
      "93_features.layer3.2.ReLU_relu                            -  \n",
      "94_features.layer3.2.Conv2d_conv2               603.979776M  \n",
      "95_features.layer3.2.BatchNorm2d_bn2                  256.0  \n",
      "96_features.layer3.2.ReLU_relu                            -  \n",
      "97_features.layer3.2.Conv2d_conv3               268.435456M  \n",
      "98_features.layer3.2.BatchNorm2d_bn3                 1.024k  \n",
      "99_features.layer3.2.ReLU_relu                            -  \n",
      "100_features.layer3.3.Conv2d_conv1              268.435456M  \n",
      "101_features.layer3.3.BatchNorm2d_bn1                 256.0  \n",
      "102_features.layer3.3.ReLU_relu                           -  \n",
      "103_features.layer3.3.Conv2d_conv2              603.979776M  \n",
      "104_features.layer3.3.BatchNorm2d_bn2                 256.0  \n",
      "105_features.layer3.3.ReLU_relu                           -  \n",
      "106_features.layer3.3.Conv2d_conv3              268.435456M  \n",
      "107_features.layer3.3.BatchNorm2d_bn3                1.024k  \n",
      "108_features.layer3.3.ReLU_relu                           -  \n",
      "109_features.layer3.4.Conv2d_conv1              268.435456M  \n",
      "110_features.layer3.4.BatchNorm2d_bn1                 256.0  \n",
      "111_features.layer3.4.ReLU_relu                           -  \n",
      "112_features.layer3.4.Conv2d_conv2              603.979776M  \n",
      "113_features.layer3.4.BatchNorm2d_bn2                 256.0  \n",
      "114_features.layer3.4.ReLU_relu                           -  \n",
      "115_features.layer3.4.Conv2d_conv3              268.435456M  \n",
      "116_features.layer3.4.BatchNorm2d_bn3                1.024k  \n",
      "117_features.layer3.4.ReLU_relu                           -  \n",
      "118_features.layer3.5.Conv2d_conv1              268.435456M  \n",
      "119_features.layer3.5.BatchNorm2d_bn1                 256.0  \n",
      "120_features.layer3.5.ReLU_relu                           -  \n",
      "121_features.layer3.5.Conv2d_conv2              603.979776M  \n",
      "122_features.layer3.5.BatchNorm2d_bn2                 256.0  \n",
      "123_features.layer3.5.ReLU_relu                           -  \n",
      "124_features.layer3.5.Conv2d_conv3              268.435456M  \n",
      "125_features.layer3.5.BatchNorm2d_bn3                1.024k  \n",
      "126_features.layer3.5.ReLU_relu                           -  \n",
      "127_features.layer4.0.Conv2d_conv1              536.870912M  \n",
      "128_features.layer4.0.BatchNorm2d_bn1                 512.0  \n",
      "129_features.layer4.0.ReLU_relu                           -  \n",
      "130_features.layer4.0.Conv2d_conv2              603.979776M  \n",
      "131_features.layer4.0.BatchNorm2d_bn2                 512.0  \n",
      "132_features.layer4.0.ReLU_relu                           -  \n",
      "133_features.layer4.0.Conv2d_conv3              268.435456M  \n",
      "134_features.layer4.0.BatchNorm2d_bn3                2.048k  \n",
      "135_features.layer4.0.downsample.Conv2d_0       536.870912M  \n",
      "136_features.layer4.0.downsample.BatchNorm2d_1       2.048k  \n",
      "137_features.layer4.0.ReLU_relu                           -  \n",
      "138_features.layer4.1.Conv2d_conv1              268.435456M  \n",
      "139_features.layer4.1.BatchNorm2d_bn1                 512.0  \n",
      "140_features.layer4.1.ReLU_relu                           -  \n",
      "141_features.layer4.1.Conv2d_conv2              603.979776M  \n",
      "142_features.layer4.1.BatchNorm2d_bn2                 512.0  \n",
      "143_features.layer4.1.ReLU_relu                           -  \n",
      "144_features.layer4.1.Conv2d_conv3              268.435456M  \n",
      "145_features.layer4.1.BatchNorm2d_bn3                2.048k  \n",
      "146_features.layer4.1.ReLU_relu                           -  \n",
      "147_features.layer4.2.Conv2d_conv1              268.435456M  \n",
      "148_features.layer4.2.BatchNorm2d_bn1                 512.0  \n",
      "149_features.layer4.2.ReLU_relu                           -  \n",
      "150_features.layer4.2.Conv2d_conv2              603.979776M  \n",
      "151_features.layer4.2.BatchNorm2d_bn2                 512.0  \n",
      "152_features.layer4.2.ReLU_relu                           -  \n",
      "153_features.layer4.2.Conv2d_conv3              268.435456M  \n",
      "154_features.layer4.2.BatchNorm2d_bn3                2.048k  \n",
      "155_features.layer4.2.ReLU_relu                           -  \n",
      "156_pool                                                  -  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "                             Totals\n",
      "Total params             23.508032M\n",
      "Trainable params         23.508032M\n",
      "Non-trainable params            0.0\n",
      "Mult-Adds             21.353228224G\n",
      "==============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_features.Conv2d_conv1</th>\n",
       "      <td>[3, 64, 7, 7]</td>\n",
       "      <td>[1, 64, 256, 256]</td>\n",
       "      <td>9408.0</td>\n",
       "      <td>616562688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_features.BatchNorm2d_bn1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 256, 256]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_features.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 256, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_features.MaxPool2d_maxpool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_features.layer1.0.Conv2d_conv1</th>\n",
       "      <td>[64, 64, 1, 1]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>67108864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152_features.layer4.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153_features.layer4.2.Conv2d_conv3</th>\n",
       "      <td>[512, 2048, 1, 1]</td>\n",
       "      <td>[1, 2048, 16, 16]</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>268435456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154_features.layer4.2.BatchNorm2d_bn3</th>\n",
       "      <td>[2048]</td>\n",
       "      <td>[1, 2048, 16, 16]</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155_features.layer4.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 2048, 16, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156_pool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 2048, 1, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Kernel Shape       Output Shape  \\\n",
       "Layer                                                                         \n",
       "0_features.Conv2d_conv1                    [3, 64, 7, 7]  [1, 64, 256, 256]   \n",
       "1_features.BatchNorm2d_bn1                          [64]  [1, 64, 256, 256]   \n",
       "2_features.ReLU_relu                                   -  [1, 64, 256, 256]   \n",
       "3_features.MaxPool2d_maxpool                           -  [1, 64, 128, 128]   \n",
       "4_features.layer1.0.Conv2d_conv1          [64, 64, 1, 1]  [1, 64, 128, 128]   \n",
       "...                                                  ...                ...   \n",
       "152_features.layer4.2.ReLU_relu                        -   [1, 512, 16, 16]   \n",
       "153_features.layer4.2.Conv2d_conv3     [512, 2048, 1, 1]  [1, 2048, 16, 16]   \n",
       "154_features.layer4.2.BatchNorm2d_bn3             [2048]  [1, 2048, 16, 16]   \n",
       "155_features.layer4.2.ReLU_relu                        -  [1, 2048, 16, 16]   \n",
       "156_pool                                               -    [1, 2048, 1, 1]   \n",
       "\n",
       "                                          Params    Mult-Adds  \n",
       "Layer                                                          \n",
       "0_features.Conv2d_conv1                   9408.0  616562688.0  \n",
       "1_features.BatchNorm2d_bn1                 128.0         64.0  \n",
       "2_features.ReLU_relu                         NaN          NaN  \n",
       "3_features.MaxPool2d_maxpool                 NaN          NaN  \n",
       "4_features.layer1.0.Conv2d_conv1          4096.0   67108864.0  \n",
       "...                                          ...          ...  \n",
       "152_features.layer4.2.ReLU_relu              NaN          NaN  \n",
       "153_features.layer4.2.Conv2d_conv3     1048576.0  268435456.0  \n",
       "154_features.layer4.2.BatchNorm2d_bn3     4096.0       2048.0  \n",
       "155_features.layer4.2.ReLU_relu              NaN          NaN  \n",
       "156_pool                                     NaN          NaN  \n",
       "\n",
       "[157 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, torch.zeros((1,3,512,512), device=\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6776bd82-0f1f-443c-9dc7-e1cec8da3045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================================\n",
      "                                          Kernel Shape       Output Shape  \\\n",
      "Layer                                                                       \n",
      "0_conv1                                  [3, 64, 7, 7]  [1, 64, 256, 256]   \n",
      "1_bn1                                             [64]  [1, 64, 256, 256]   \n",
      "2_relu                                               -  [1, 64, 256, 256]   \n",
      "3_maxpool                                            -  [1, 64, 128, 128]   \n",
      "4_layer1.0.Conv2d_conv1                 [64, 64, 3, 3]  [1, 64, 128, 128]   \n",
      "5_layer1.0.BatchNorm2d_bn1                        [64]  [1, 64, 128, 128]   \n",
      "6_layer1.0.ReLU_relu                                 -  [1, 64, 128, 128]   \n",
      "7_layer1.0.Conv2d_conv2                 [64, 64, 3, 3]  [1, 64, 128, 128]   \n",
      "8_layer1.0.BatchNorm2d_bn2                        [64]  [1, 64, 128, 128]   \n",
      "9_layer1.0.ReLU_relu                                 -  [1, 64, 128, 128]   \n",
      "10_layer1.1.Conv2d_conv1                [64, 64, 3, 3]  [1, 64, 128, 128]   \n",
      "11_layer1.1.BatchNorm2d_bn1                       [64]  [1, 64, 128, 128]   \n",
      "12_layer1.1.ReLU_relu                                -  [1, 64, 128, 128]   \n",
      "13_layer1.1.Conv2d_conv2                [64, 64, 3, 3]  [1, 64, 128, 128]   \n",
      "14_layer1.1.BatchNorm2d_bn2                       [64]  [1, 64, 128, 128]   \n",
      "15_layer1.1.ReLU_relu                                -  [1, 64, 128, 128]   \n",
      "16_layer2.0.Conv2d_conv1               [64, 128, 3, 3]   [1, 128, 64, 64]   \n",
      "17_layer2.0.BatchNorm2d_bn1                      [128]   [1, 128, 64, 64]   \n",
      "18_layer2.0.ReLU_relu                                -   [1, 128, 64, 64]   \n",
      "19_layer2.0.Conv2d_conv2              [128, 128, 3, 3]   [1, 128, 64, 64]   \n",
      "20_layer2.0.BatchNorm2d_bn2                      [128]   [1, 128, 64, 64]   \n",
      "21_layer2.0.downsample.Conv2d_0        [64, 128, 1, 1]   [1, 128, 64, 64]   \n",
      "22_layer2.0.downsample.BatchNorm2d_1             [128]   [1, 128, 64, 64]   \n",
      "23_layer2.0.ReLU_relu                                -   [1, 128, 64, 64]   \n",
      "24_layer2.1.Conv2d_conv1              [128, 128, 3, 3]   [1, 128, 64, 64]   \n",
      "25_layer2.1.BatchNorm2d_bn1                      [128]   [1, 128, 64, 64]   \n",
      "26_layer2.1.ReLU_relu                                -   [1, 128, 64, 64]   \n",
      "27_layer2.1.Conv2d_conv2              [128, 128, 3, 3]   [1, 128, 64, 64]   \n",
      "28_layer2.1.BatchNorm2d_bn2                      [128]   [1, 128, 64, 64]   \n",
      "29_layer2.1.ReLU_relu                                -   [1, 128, 64, 64]   \n",
      "30_layer3.0.Conv2d_conv1              [128, 256, 3, 3]   [1, 256, 32, 32]   \n",
      "31_layer3.0.BatchNorm2d_bn1                      [256]   [1, 256, 32, 32]   \n",
      "32_layer3.0.ReLU_relu                                -   [1, 256, 32, 32]   \n",
      "33_layer3.0.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 32, 32]   \n",
      "34_layer3.0.BatchNorm2d_bn2                      [256]   [1, 256, 32, 32]   \n",
      "35_layer3.0.downsample.Conv2d_0       [128, 256, 1, 1]   [1, 256, 32, 32]   \n",
      "36_layer3.0.downsample.BatchNorm2d_1             [256]   [1, 256, 32, 32]   \n",
      "37_layer3.0.ReLU_relu                                -   [1, 256, 32, 32]   \n",
      "38_layer3.1.Conv2d_conv1              [256, 256, 3, 3]   [1, 256, 32, 32]   \n",
      "39_layer3.1.BatchNorm2d_bn1                      [256]   [1, 256, 32, 32]   \n",
      "40_layer3.1.ReLU_relu                                -   [1, 256, 32, 32]   \n",
      "41_layer3.1.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 32, 32]   \n",
      "42_layer3.1.BatchNorm2d_bn2                      [256]   [1, 256, 32, 32]   \n",
      "43_layer3.1.ReLU_relu                                -   [1, 256, 32, 32]   \n",
      "44_layer4.0.Conv2d_conv1              [256, 512, 3, 3]   [1, 512, 16, 16]   \n",
      "45_layer4.0.BatchNorm2d_bn1                      [512]   [1, 512, 16, 16]   \n",
      "46_layer4.0.ReLU_relu                                -   [1, 512, 16, 16]   \n",
      "47_layer4.0.Conv2d_conv2              [512, 512, 3, 3]   [1, 512, 16, 16]   \n",
      "48_layer4.0.BatchNorm2d_bn2                      [512]   [1, 512, 16, 16]   \n",
      "49_layer4.0.downsample.Conv2d_0       [256, 512, 1, 1]   [1, 512, 16, 16]   \n",
      "50_layer4.0.downsample.BatchNorm2d_1             [512]   [1, 512, 16, 16]   \n",
      "51_layer4.0.ReLU_relu                                -   [1, 512, 16, 16]   \n",
      "52_layer4.1.Conv2d_conv1              [512, 512, 3, 3]   [1, 512, 16, 16]   \n",
      "53_layer4.1.BatchNorm2d_bn1                      [512]   [1, 512, 16, 16]   \n",
      "54_layer4.1.ReLU_relu                                -   [1, 512, 16, 16]   \n",
      "55_layer4.1.Conv2d_conv2              [512, 512, 3, 3]   [1, 512, 16, 16]   \n",
      "56_layer4.1.BatchNorm2d_bn2                      [512]   [1, 512, 16, 16]   \n",
      "57_layer4.1.ReLU_relu                                -   [1, 512, 16, 16]   \n",
      "58_avgpool                                           -     [1, 512, 1, 1]   \n",
      "59_fc                                      [512, 1000]          [1, 1000]   \n",
      "\n",
      "                                         Params    Mult-Adds  \n",
      "Layer                                                         \n",
      "0_conv1                                  9.408k  616.562688M  \n",
      "1_bn1                                     128.0         64.0  \n",
      "2_relu                                        -            -  \n",
      "3_maxpool                                     -            -  \n",
      "4_layer1.0.Conv2d_conv1                 36.864k  603.979776M  \n",
      "5_layer1.0.BatchNorm2d_bn1                128.0         64.0  \n",
      "6_layer1.0.ReLU_relu                          -            -  \n",
      "7_layer1.0.Conv2d_conv2                 36.864k  603.979776M  \n",
      "8_layer1.0.BatchNorm2d_bn2                128.0         64.0  \n",
      "9_layer1.0.ReLU_relu                          -            -  \n",
      "10_layer1.1.Conv2d_conv1                36.864k  603.979776M  \n",
      "11_layer1.1.BatchNorm2d_bn1               128.0         64.0  \n",
      "12_layer1.1.ReLU_relu                         -            -  \n",
      "13_layer1.1.Conv2d_conv2                36.864k  603.979776M  \n",
      "14_layer1.1.BatchNorm2d_bn2               128.0         64.0  \n",
      "15_layer1.1.ReLU_relu                         -            -  \n",
      "16_layer2.0.Conv2d_conv1                73.728k  301.989888M  \n",
      "17_layer2.0.BatchNorm2d_bn1               256.0        128.0  \n",
      "18_layer2.0.ReLU_relu                         -            -  \n",
      "19_layer2.0.Conv2d_conv2               147.456k  603.979776M  \n",
      "20_layer2.0.BatchNorm2d_bn2               256.0        128.0  \n",
      "21_layer2.0.downsample.Conv2d_0          8.192k   33.554432M  \n",
      "22_layer2.0.downsample.BatchNorm2d_1      256.0        128.0  \n",
      "23_layer2.0.ReLU_relu                         -            -  \n",
      "24_layer2.1.Conv2d_conv1               147.456k  603.979776M  \n",
      "25_layer2.1.BatchNorm2d_bn1               256.0        128.0  \n",
      "26_layer2.1.ReLU_relu                         -            -  \n",
      "27_layer2.1.Conv2d_conv2               147.456k  603.979776M  \n",
      "28_layer2.1.BatchNorm2d_bn2               256.0        128.0  \n",
      "29_layer2.1.ReLU_relu                         -            -  \n",
      "30_layer3.0.Conv2d_conv1               294.912k  301.989888M  \n",
      "31_layer3.0.BatchNorm2d_bn1               512.0        256.0  \n",
      "32_layer3.0.ReLU_relu                         -            -  \n",
      "33_layer3.0.Conv2d_conv2               589.824k  603.979776M  \n",
      "34_layer3.0.BatchNorm2d_bn2               512.0        256.0  \n",
      "35_layer3.0.downsample.Conv2d_0         32.768k   33.554432M  \n",
      "36_layer3.0.downsample.BatchNorm2d_1      512.0        256.0  \n",
      "37_layer3.0.ReLU_relu                         -            -  \n",
      "38_layer3.1.Conv2d_conv1               589.824k  603.979776M  \n",
      "39_layer3.1.BatchNorm2d_bn1               512.0        256.0  \n",
      "40_layer3.1.ReLU_relu                         -            -  \n",
      "41_layer3.1.Conv2d_conv2               589.824k  603.979776M  \n",
      "42_layer3.1.BatchNorm2d_bn2               512.0        256.0  \n",
      "43_layer3.1.ReLU_relu                         -            -  \n",
      "44_layer4.0.Conv2d_conv1              1.179648M  301.989888M  \n",
      "45_layer4.0.BatchNorm2d_bn1              1.024k        512.0  \n",
      "46_layer4.0.ReLU_relu                         -            -  \n",
      "47_layer4.0.Conv2d_conv2              2.359296M  603.979776M  \n",
      "48_layer4.0.BatchNorm2d_bn2              1.024k        512.0  \n",
      "49_layer4.0.downsample.Conv2d_0        131.072k   33.554432M  \n",
      "50_layer4.0.downsample.BatchNorm2d_1     1.024k        512.0  \n",
      "51_layer4.0.ReLU_relu                         -            -  \n",
      "52_layer4.1.Conv2d_conv1              2.359296M  603.979776M  \n",
      "53_layer4.1.BatchNorm2d_bn1              1.024k        512.0  \n",
      "54_layer4.1.ReLU_relu                         -            -  \n",
      "55_layer4.1.Conv2d_conv2              2.359296M  603.979776M  \n",
      "56_layer4.1.BatchNorm2d_bn2              1.024k        512.0  \n",
      "57_layer4.1.ReLU_relu                         -            -  \n",
      "58_avgpool                                    -            -  \n",
      "59_fc                                    513.0k       512.0k  \n",
      "-------------------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params            11.689512M\n",
      "Trainable params        11.689512M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             9.475449536G\n",
      "=================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_conv1</th>\n",
       "      <td>[3, 64, 7, 7]</td>\n",
       "      <td>[1, 64, 256, 256]</td>\n",
       "      <td>9408.0</td>\n",
       "      <td>616562688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_bn1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 256, 256]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 256, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_maxpool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_layer1.0.Conv2d_conv1</th>\n",
       "      <td>[64, 64, 3, 3]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_layer1.0.BatchNorm2d_bn1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_layer1.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_layer1.0.Conv2d_conv2</th>\n",
       "      <td>[64, 64, 3, 3]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_layer1.0.BatchNorm2d_bn2</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_layer1.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_layer1.1.Conv2d_conv1</th>\n",
       "      <td>[64, 64, 3, 3]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_layer1.1.BatchNorm2d_bn1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_layer1.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_layer1.1.Conv2d_conv2</th>\n",
       "      <td>[64, 64, 3, 3]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_layer1.1.BatchNorm2d_bn2</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_layer1.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_layer2.0.Conv2d_conv1</th>\n",
       "      <td>[64, 128, 3, 3]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>73728.0</td>\n",
       "      <td>301989888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_layer2.0.BatchNorm2d_bn1</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18_layer2.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19_layer2.0.Conv2d_conv2</th>\n",
       "      <td>[128, 128, 3, 3]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_layer2.0.BatchNorm2d_bn2</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21_layer2.0.downsample.Conv2d_0</th>\n",
       "      <td>[64, 128, 1, 1]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>33554432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22_layer2.0.downsample.BatchNorm2d_1</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23_layer2.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24_layer2.1.Conv2d_conv1</th>\n",
       "      <td>[128, 128, 3, 3]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25_layer2.1.BatchNorm2d_bn1</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26_layer2.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27_layer2.1.Conv2d_conv2</th>\n",
       "      <td>[128, 128, 3, 3]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28_layer2.1.BatchNorm2d_bn2</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29_layer2.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 64, 64]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30_layer3.0.Conv2d_conv1</th>\n",
       "      <td>[128, 256, 3, 3]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>294912.0</td>\n",
       "      <td>301989888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31_layer3.0.BatchNorm2d_bn1</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32_layer3.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33_layer3.0.Conv2d_conv2</th>\n",
       "      <td>[256, 256, 3, 3]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34_layer3.0.BatchNorm2d_bn2</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35_layer3.0.downsample.Conv2d_0</th>\n",
       "      <td>[128, 256, 1, 1]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>33554432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36_layer3.0.downsample.BatchNorm2d_1</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37_layer3.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38_layer3.1.Conv2d_conv1</th>\n",
       "      <td>[256, 256, 3, 3]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39_layer3.1.BatchNorm2d_bn1</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40_layer3.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41_layer3.1.Conv2d_conv2</th>\n",
       "      <td>[256, 256, 3, 3]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42_layer3.1.BatchNorm2d_bn2</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43_layer3.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 256, 32, 32]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44_layer4.0.Conv2d_conv1</th>\n",
       "      <td>[256, 512, 3, 3]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>1179648.0</td>\n",
       "      <td>301989888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45_layer4.0.BatchNorm2d_bn1</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46_layer4.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47_layer4.0.Conv2d_conv2</th>\n",
       "      <td>[512, 512, 3, 3]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>2359296.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48_layer4.0.BatchNorm2d_bn2</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49_layer4.0.downsample.Conv2d_0</th>\n",
       "      <td>[256, 512, 1, 1]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>33554432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50_layer4.0.downsample.BatchNorm2d_1</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51_layer4.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52_layer4.1.Conv2d_conv1</th>\n",
       "      <td>[512, 512, 3, 3]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>2359296.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53_layer4.1.BatchNorm2d_bn1</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54_layer4.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_layer4.1.Conv2d_conv2</th>\n",
       "      <td>[512, 512, 3, 3]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>2359296.0</td>\n",
       "      <td>603979776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56_layer4.1.BatchNorm2d_bn2</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57_layer4.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 512, 16, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58_avgpool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 512, 1, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59_fc</th>\n",
       "      <td>[512, 1000]</td>\n",
       "      <td>[1, 1000]</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>512000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Kernel Shape       Output Shape  \\\n",
       "Layer                                                                       \n",
       "0_conv1                                  [3, 64, 7, 7]  [1, 64, 256, 256]   \n",
       "1_bn1                                             [64]  [1, 64, 256, 256]   \n",
       "2_relu                                               -  [1, 64, 256, 256]   \n",
       "3_maxpool                                            -  [1, 64, 128, 128]   \n",
       "4_layer1.0.Conv2d_conv1                 [64, 64, 3, 3]  [1, 64, 128, 128]   \n",
       "5_layer1.0.BatchNorm2d_bn1                        [64]  [1, 64, 128, 128]   \n",
       "6_layer1.0.ReLU_relu                                 -  [1, 64, 128, 128]   \n",
       "7_layer1.0.Conv2d_conv2                 [64, 64, 3, 3]  [1, 64, 128, 128]   \n",
       "8_layer1.0.BatchNorm2d_bn2                        [64]  [1, 64, 128, 128]   \n",
       "9_layer1.0.ReLU_relu                                 -  [1, 64, 128, 128]   \n",
       "10_layer1.1.Conv2d_conv1                [64, 64, 3, 3]  [1, 64, 128, 128]   \n",
       "11_layer1.1.BatchNorm2d_bn1                       [64]  [1, 64, 128, 128]   \n",
       "12_layer1.1.ReLU_relu                                -  [1, 64, 128, 128]   \n",
       "13_layer1.1.Conv2d_conv2                [64, 64, 3, 3]  [1, 64, 128, 128]   \n",
       "14_layer1.1.BatchNorm2d_bn2                       [64]  [1, 64, 128, 128]   \n",
       "15_layer1.1.ReLU_relu                                -  [1, 64, 128, 128]   \n",
       "16_layer2.0.Conv2d_conv1               [64, 128, 3, 3]   [1, 128, 64, 64]   \n",
       "17_layer2.0.BatchNorm2d_bn1                      [128]   [1, 128, 64, 64]   \n",
       "18_layer2.0.ReLU_relu                                -   [1, 128, 64, 64]   \n",
       "19_layer2.0.Conv2d_conv2              [128, 128, 3, 3]   [1, 128, 64, 64]   \n",
       "20_layer2.0.BatchNorm2d_bn2                      [128]   [1, 128, 64, 64]   \n",
       "21_layer2.0.downsample.Conv2d_0        [64, 128, 1, 1]   [1, 128, 64, 64]   \n",
       "22_layer2.0.downsample.BatchNorm2d_1             [128]   [1, 128, 64, 64]   \n",
       "23_layer2.0.ReLU_relu                                -   [1, 128, 64, 64]   \n",
       "24_layer2.1.Conv2d_conv1              [128, 128, 3, 3]   [1, 128, 64, 64]   \n",
       "25_layer2.1.BatchNorm2d_bn1                      [128]   [1, 128, 64, 64]   \n",
       "26_layer2.1.ReLU_relu                                -   [1, 128, 64, 64]   \n",
       "27_layer2.1.Conv2d_conv2              [128, 128, 3, 3]   [1, 128, 64, 64]   \n",
       "28_layer2.1.BatchNorm2d_bn2                      [128]   [1, 128, 64, 64]   \n",
       "29_layer2.1.ReLU_relu                                -   [1, 128, 64, 64]   \n",
       "30_layer3.0.Conv2d_conv1              [128, 256, 3, 3]   [1, 256, 32, 32]   \n",
       "31_layer3.0.BatchNorm2d_bn1                      [256]   [1, 256, 32, 32]   \n",
       "32_layer3.0.ReLU_relu                                -   [1, 256, 32, 32]   \n",
       "33_layer3.0.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 32, 32]   \n",
       "34_layer3.0.BatchNorm2d_bn2                      [256]   [1, 256, 32, 32]   \n",
       "35_layer3.0.downsample.Conv2d_0       [128, 256, 1, 1]   [1, 256, 32, 32]   \n",
       "36_layer3.0.downsample.BatchNorm2d_1             [256]   [1, 256, 32, 32]   \n",
       "37_layer3.0.ReLU_relu                                -   [1, 256, 32, 32]   \n",
       "38_layer3.1.Conv2d_conv1              [256, 256, 3, 3]   [1, 256, 32, 32]   \n",
       "39_layer3.1.BatchNorm2d_bn1                      [256]   [1, 256, 32, 32]   \n",
       "40_layer3.1.ReLU_relu                                -   [1, 256, 32, 32]   \n",
       "41_layer3.1.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 32, 32]   \n",
       "42_layer3.1.BatchNorm2d_bn2                      [256]   [1, 256, 32, 32]   \n",
       "43_layer3.1.ReLU_relu                                -   [1, 256, 32, 32]   \n",
       "44_layer4.0.Conv2d_conv1              [256, 512, 3, 3]   [1, 512, 16, 16]   \n",
       "45_layer4.0.BatchNorm2d_bn1                      [512]   [1, 512, 16, 16]   \n",
       "46_layer4.0.ReLU_relu                                -   [1, 512, 16, 16]   \n",
       "47_layer4.0.Conv2d_conv2              [512, 512, 3, 3]   [1, 512, 16, 16]   \n",
       "48_layer4.0.BatchNorm2d_bn2                      [512]   [1, 512, 16, 16]   \n",
       "49_layer4.0.downsample.Conv2d_0       [256, 512, 1, 1]   [1, 512, 16, 16]   \n",
       "50_layer4.0.downsample.BatchNorm2d_1             [512]   [1, 512, 16, 16]   \n",
       "51_layer4.0.ReLU_relu                                -   [1, 512, 16, 16]   \n",
       "52_layer4.1.Conv2d_conv1              [512, 512, 3, 3]   [1, 512, 16, 16]   \n",
       "53_layer4.1.BatchNorm2d_bn1                      [512]   [1, 512, 16, 16]   \n",
       "54_layer4.1.ReLU_relu                                -   [1, 512, 16, 16]   \n",
       "55_layer4.1.Conv2d_conv2              [512, 512, 3, 3]   [1, 512, 16, 16]   \n",
       "56_layer4.1.BatchNorm2d_bn2                      [512]   [1, 512, 16, 16]   \n",
       "57_layer4.1.ReLU_relu                                -   [1, 512, 16, 16]   \n",
       "58_avgpool                                           -     [1, 512, 1, 1]   \n",
       "59_fc                                      [512, 1000]          [1, 1000]   \n",
       "\n",
       "                                         Params    Mult-Adds  \n",
       "Layer                                                         \n",
       "0_conv1                                  9408.0  616562688.0  \n",
       "1_bn1                                     128.0         64.0  \n",
       "2_relu                                      NaN          NaN  \n",
       "3_maxpool                                   NaN          NaN  \n",
       "4_layer1.0.Conv2d_conv1                 36864.0  603979776.0  \n",
       "5_layer1.0.BatchNorm2d_bn1                128.0         64.0  \n",
       "6_layer1.0.ReLU_relu                        NaN          NaN  \n",
       "7_layer1.0.Conv2d_conv2                 36864.0  603979776.0  \n",
       "8_layer1.0.BatchNorm2d_bn2                128.0         64.0  \n",
       "9_layer1.0.ReLU_relu                        NaN          NaN  \n",
       "10_layer1.1.Conv2d_conv1                36864.0  603979776.0  \n",
       "11_layer1.1.BatchNorm2d_bn1               128.0         64.0  \n",
       "12_layer1.1.ReLU_relu                       NaN          NaN  \n",
       "13_layer1.1.Conv2d_conv2                36864.0  603979776.0  \n",
       "14_layer1.1.BatchNorm2d_bn2               128.0         64.0  \n",
       "15_layer1.1.ReLU_relu                       NaN          NaN  \n",
       "16_layer2.0.Conv2d_conv1                73728.0  301989888.0  \n",
       "17_layer2.0.BatchNorm2d_bn1               256.0        128.0  \n",
       "18_layer2.0.ReLU_relu                       NaN          NaN  \n",
       "19_layer2.0.Conv2d_conv2               147456.0  603979776.0  \n",
       "20_layer2.0.BatchNorm2d_bn2               256.0        128.0  \n",
       "21_layer2.0.downsample.Conv2d_0          8192.0   33554432.0  \n",
       "22_layer2.0.downsample.BatchNorm2d_1      256.0        128.0  \n",
       "23_layer2.0.ReLU_relu                       NaN          NaN  \n",
       "24_layer2.1.Conv2d_conv1               147456.0  603979776.0  \n",
       "25_layer2.1.BatchNorm2d_bn1               256.0        128.0  \n",
       "26_layer2.1.ReLU_relu                       NaN          NaN  \n",
       "27_layer2.1.Conv2d_conv2               147456.0  603979776.0  \n",
       "28_layer2.1.BatchNorm2d_bn2               256.0        128.0  \n",
       "29_layer2.1.ReLU_relu                       NaN          NaN  \n",
       "30_layer3.0.Conv2d_conv1               294912.0  301989888.0  \n",
       "31_layer3.0.BatchNorm2d_bn1               512.0        256.0  \n",
       "32_layer3.0.ReLU_relu                       NaN          NaN  \n",
       "33_layer3.0.Conv2d_conv2               589824.0  603979776.0  \n",
       "34_layer3.0.BatchNorm2d_bn2               512.0        256.0  \n",
       "35_layer3.0.downsample.Conv2d_0         32768.0   33554432.0  \n",
       "36_layer3.0.downsample.BatchNorm2d_1      512.0        256.0  \n",
       "37_layer3.0.ReLU_relu                       NaN          NaN  \n",
       "38_layer3.1.Conv2d_conv1               589824.0  603979776.0  \n",
       "39_layer3.1.BatchNorm2d_bn1               512.0        256.0  \n",
       "40_layer3.1.ReLU_relu                       NaN          NaN  \n",
       "41_layer3.1.Conv2d_conv2               589824.0  603979776.0  \n",
       "42_layer3.1.BatchNorm2d_bn2               512.0        256.0  \n",
       "43_layer3.1.ReLU_relu                       NaN          NaN  \n",
       "44_layer4.0.Conv2d_conv1              1179648.0  301989888.0  \n",
       "45_layer4.0.BatchNorm2d_bn1              1024.0        512.0  \n",
       "46_layer4.0.ReLU_relu                       NaN          NaN  \n",
       "47_layer4.0.Conv2d_conv2              2359296.0  603979776.0  \n",
       "48_layer4.0.BatchNorm2d_bn2              1024.0        512.0  \n",
       "49_layer4.0.downsample.Conv2d_0        131072.0   33554432.0  \n",
       "50_layer4.0.downsample.BatchNorm2d_1     1024.0        512.0  \n",
       "51_layer4.0.ReLU_relu                       NaN          NaN  \n",
       "52_layer4.1.Conv2d_conv1              2359296.0  603979776.0  \n",
       "53_layer4.1.BatchNorm2d_bn1              1024.0        512.0  \n",
       "54_layer4.1.ReLU_relu                       NaN          NaN  \n",
       "55_layer4.1.Conv2d_conv2              2359296.0  603979776.0  \n",
       "56_layer4.1.BatchNorm2d_bn2              1024.0        512.0  \n",
       "57_layer4.1.ReLU_relu                       NaN          NaN  \n",
       "58_avgpool                                  NaN          NaN  \n",
       "59_fc                                  513000.0     512000.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, torch.zeros((1,3,512,512), device=\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c74c62-2b6d-4266-b10a-0726d9ef3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d321ed9e-7887-4cc1-82d6-0df8a7d46ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    input = torch.FloatTensor(2, 3, 512, 512).uniform_(0, 1.0).cuda()\n",
    "    input = Variable(input)\n",
    "    target = torch.FloatTensor(2, 2048, 1, 1).uniform_(0, 1.0).cuda()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(input)\n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e18b7f8-2a6b-4563-9e4f-a0234b540a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nnunet.network_architecture.generic_UNet import Generic_UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd80cb8b-b1a1-4454-837a-8eb5d8916a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = Generic_UNet.use_this_for_batch_size_computation_2D * Generic_UNet.DEFAULT_BATCH_SIZE_2D / 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa9e1fb-839f-4bf8-af6e-794d9a8a5d1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Generic_UNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m here \u001b[38;5;241m=\u001b[39m \u001b[43mGeneric_UNet\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_approx_vram_consumption(\n\u001b[1;32m      2\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m),\n\u001b[1;32m      3\u001b[0m     num_pool_per_axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m),\n\u001b[1;32m      4\u001b[0m     base_num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      5\u001b[0m     max_num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m      6\u001b[0m     num_modalities\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m,\n\u001b[1;32m      8\u001b[0m     deep_supervision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     pool_op_kernel_sizes\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]]\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Generic_UNet' is not defined"
     ]
    }
   ],
   "source": [
    "here = Generic_UNet.compute_approx_vram_consumption(\n",
    "    patch_size=(1024, 1024),\n",
    "    num_pool_per_axis=(7, 7),\n",
    "    base_num_features=32,\n",
    "    max_num_features=512,\n",
    "    num_modalities=1,\n",
    "    num_classes=7,\n",
    "    deep_supervision=True,\n",
    "    pool_op_kernel_sizes=[[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bbfd346-9380-4af0-8ce9-37826e1ab2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnunet = Generic_UNet(input_channels=3, base_num_features=32, num_classes=6, num_pool=7).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ad3c10-17e9-4108-8621-b700e8348ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================================================================\n",
      "                                                        Kernel Shape  \\\n",
      "Layer                                                                  \n",
      "0_conv_blocks_context.0.blocks.0.Conv2d_conv           [3, 32, 3, 3]   \n",
      "1_conv_blocks_context.0.blocks.0.Dropout2d_dropout                 -   \n",
      "2_conv_blocks_context.0.blocks.0.BatchNorm2d_in...              [32]   \n",
      "3_conv_blocks_context.0.blocks.0.LeakyReLU_lrelu                   -   \n",
      "4_conv_blocks_context.0.blocks.1.Conv2d_conv          [32, 32, 3, 3]   \n",
      "5_conv_blocks_context.0.blocks.1.Dropout2d_dropout                 -   \n",
      "6_conv_blocks_context.0.blocks.1.BatchNorm2d_in...              [32]   \n",
      "7_conv_blocks_context.0.blocks.1.LeakyReLU_lrelu                   -   \n",
      "8_td.MaxPool2d_0                                                   -   \n",
      "9_conv_blocks_context.1.blocks.0.Conv2d_conv          [32, 64, 3, 3]   \n",
      "10_conv_blocks_context.1.blocks.0.Dropout2d_dro...                 -   \n",
      "11_conv_blocks_context.1.blocks.0.BatchNorm2d_i...              [64]   \n",
      "12_conv_blocks_context.1.blocks.0.LeakyReLU_lrelu                  -   \n",
      "13_conv_blocks_context.1.blocks.1.Conv2d_conv         [64, 64, 3, 3]   \n",
      "14_conv_blocks_context.1.blocks.1.Dropout2d_dro...                 -   \n",
      "15_conv_blocks_context.1.blocks.1.BatchNorm2d_i...              [64]   \n",
      "16_conv_blocks_context.1.blocks.1.LeakyReLU_lrelu                  -   \n",
      "17_td.MaxPool2d_1                                                  -   \n",
      "18_conv_blocks_context.2.blocks.0.Conv2d_conv        [64, 128, 3, 3]   \n",
      "19_conv_blocks_context.2.blocks.0.Dropout2d_dro...                 -   \n",
      "20_conv_blocks_context.2.blocks.0.BatchNorm2d_i...             [128]   \n",
      "21_conv_blocks_context.2.blocks.0.LeakyReLU_lrelu                  -   \n",
      "22_conv_blocks_context.2.blocks.1.Conv2d_conv       [128, 128, 3, 3]   \n",
      "23_conv_blocks_context.2.blocks.1.Dropout2d_dro...                 -   \n",
      "24_conv_blocks_context.2.blocks.1.BatchNorm2d_i...             [128]   \n",
      "25_conv_blocks_context.2.blocks.1.LeakyReLU_lrelu                  -   \n",
      "26_td.MaxPool2d_2                                                  -   \n",
      "27_conv_blocks_context.3.blocks.0.Conv2d_conv       [128, 256, 3, 3]   \n",
      "28_conv_blocks_context.3.blocks.0.Dropout2d_dro...                 -   \n",
      "29_conv_blocks_context.3.blocks.0.BatchNorm2d_i...             [256]   \n",
      "30_conv_blocks_context.3.blocks.0.LeakyReLU_lrelu                  -   \n",
      "31_conv_blocks_context.3.blocks.1.Conv2d_conv       [256, 256, 3, 3]   \n",
      "32_conv_blocks_context.3.blocks.1.Dropout2d_dro...                 -   \n",
      "33_conv_blocks_context.3.blocks.1.BatchNorm2d_i...             [256]   \n",
      "34_conv_blocks_context.3.blocks.1.LeakyReLU_lrelu                  -   \n",
      "35_td.MaxPool2d_3                                                  -   \n",
      "36_conv_blocks_context.4.blocks.0.Conv2d_conv       [256, 480, 3, 3]   \n",
      "37_conv_blocks_context.4.blocks.0.Dropout2d_dro...                 -   \n",
      "38_conv_blocks_context.4.blocks.0.BatchNorm2d_i...             [480]   \n",
      "39_conv_blocks_context.4.blocks.0.LeakyReLU_lrelu                  -   \n",
      "40_conv_blocks_context.4.blocks.1.Conv2d_conv       [480, 480, 3, 3]   \n",
      "41_conv_blocks_context.4.blocks.1.Dropout2d_dro...                 -   \n",
      "42_conv_blocks_context.4.blocks.1.BatchNorm2d_i...             [480]   \n",
      "43_conv_blocks_context.4.blocks.1.LeakyReLU_lrelu                  -   \n",
      "44_td.MaxPool2d_4                                                  -   \n",
      "45_conv_blocks_context.5.blocks.0.Conv2d_conv       [480, 480, 3, 3]   \n",
      "46_conv_blocks_context.5.blocks.0.Dropout2d_dro...                 -   \n",
      "47_conv_blocks_context.5.blocks.0.BatchNorm2d_i...             [480]   \n",
      "48_conv_blocks_context.5.blocks.0.LeakyReLU_lrelu                  -   \n",
      "49_conv_blocks_context.5.blocks.1.Conv2d_conv       [480, 480, 3, 3]   \n",
      "50_conv_blocks_context.5.blocks.1.Dropout2d_dro...                 -   \n",
      "51_conv_blocks_context.5.blocks.1.BatchNorm2d_i...             [480]   \n",
      "52_conv_blocks_context.5.blocks.1.LeakyReLU_lrelu                  -   \n",
      "53_td.MaxPool2d_5                                                  -   \n",
      "54_conv_blocks_context.6.blocks.0.Conv2d_conv       [480, 480, 3, 3]   \n",
      "55_conv_blocks_context.6.blocks.0.Dropout2d_dro...                 -   \n",
      "56_conv_blocks_context.6.blocks.0.BatchNorm2d_i...             [480]   \n",
      "57_conv_blocks_context.6.blocks.0.LeakyReLU_lrelu                  -   \n",
      "58_conv_blocks_context.6.blocks.1.Conv2d_conv       [480, 480, 3, 3]   \n",
      "59_conv_blocks_context.6.blocks.1.Dropout2d_dro...                 -   \n",
      "60_conv_blocks_context.6.blocks.1.BatchNorm2d_i...             [480]   \n",
      "61_conv_blocks_context.6.blocks.1.LeakyReLU_lrelu                  -   \n",
      "62_td.MaxPool2d_6                                                  -   \n",
      "63_conv_blocks_context.7.0.blocks.0.Conv2d_conv     [480, 480, 3, 3]   \n",
      "64_conv_blocks_context.7.0.blocks.0.Dropout2d_d...                 -   \n",
      "65_conv_blocks_context.7.0.blocks.0.BatchNorm2d...             [480]   \n",
      "66_conv_blocks_context.7.0.blocks.0.LeakyReLU_l...                 -   \n",
      "67_conv_blocks_context.7.1.blocks.0.Conv2d_conv     [480, 480, 3, 3]   \n",
      "68_conv_blocks_context.7.1.blocks.0.Dropout2d_d...                 -   \n",
      "69_conv_blocks_context.7.1.blocks.0.BatchNorm2d...             [480]   \n",
      "70_conv_blocks_context.7.1.blocks.0.LeakyReLU_l...                 -   \n",
      "71_tu.Upsample_0                                                   -   \n",
      "72_conv_blocks_localization.0.0.blocks.0.Conv2d...  [960, 480, 3, 3]   \n",
      "73_conv_blocks_localization.0.0.blocks.0.BatchN...             [480]   \n",
      "74_conv_blocks_localization.0.0.blocks.0.LeakyR...                 -   \n",
      "75_conv_blocks_localization.0.1.blocks.0.Conv2d...  [480, 480, 3, 3]   \n",
      "76_conv_blocks_localization.0.1.blocks.0.BatchN...             [480]   \n",
      "77_conv_blocks_localization.0.1.blocks.0.LeakyR...                 -   \n",
      "78_seg_outputs.Conv2d_0                               [480, 6, 1, 1]   \n",
      "79_tu.Upsample_1                                                   -   \n",
      "80_conv_blocks_localization.1.0.blocks.0.Conv2d...  [960, 480, 3, 3]   \n",
      "81_conv_blocks_localization.1.0.blocks.0.BatchN...             [480]   \n",
      "82_conv_blocks_localization.1.0.blocks.0.LeakyR...                 -   \n",
      "83_conv_blocks_localization.1.1.blocks.0.Conv2d...  [480, 480, 3, 3]   \n",
      "84_conv_blocks_localization.1.1.blocks.0.BatchN...             [480]   \n",
      "85_conv_blocks_localization.1.1.blocks.0.LeakyR...                 -   \n",
      "86_seg_outputs.Conv2d_1                               [480, 6, 1, 1]   \n",
      "87_tu.Upsample_2                                                   -   \n",
      "88_conv_blocks_localization.2.0.blocks.0.Conv2d...  [960, 480, 3, 3]   \n",
      "89_conv_blocks_localization.2.0.blocks.0.BatchN...             [480]   \n",
      "90_conv_blocks_localization.2.0.blocks.0.LeakyR...                 -   \n",
      "91_conv_blocks_localization.2.1.blocks.0.Conv2d...  [480, 256, 3, 3]   \n",
      "92_conv_blocks_localization.2.1.blocks.0.BatchN...             [256]   \n",
      "93_conv_blocks_localization.2.1.blocks.0.LeakyR...                 -   \n",
      "94_seg_outputs.Conv2d_2                               [256, 6, 1, 1]   \n",
      "95_tu.Upsample_3                                                   -   \n",
      "96_conv_blocks_localization.3.0.blocks.0.Conv2d...  [512, 256, 3, 3]   \n",
      "97_conv_blocks_localization.3.0.blocks.0.BatchN...             [256]   \n",
      "98_conv_blocks_localization.3.0.blocks.0.LeakyR...                 -   \n",
      "99_conv_blocks_localization.3.1.blocks.0.Conv2d...  [256, 128, 3, 3]   \n",
      "100_conv_blocks_localization.3.1.blocks.0.Batch...             [128]   \n",
      "101_conv_blocks_localization.3.1.blocks.0.Leaky...                 -   \n",
      "102_seg_outputs.Conv2d_3                              [128, 6, 1, 1]   \n",
      "103_tu.Upsample_4                                                  -   \n",
      "104_conv_blocks_localization.4.0.blocks.0.Conv2...  [256, 128, 3, 3]   \n",
      "105_conv_blocks_localization.4.0.blocks.0.Batch...             [128]   \n",
      "106_conv_blocks_localization.4.0.blocks.0.Leaky...                 -   \n",
      "107_conv_blocks_localization.4.1.blocks.0.Conv2...   [128, 64, 3, 3]   \n",
      "108_conv_blocks_localization.4.1.blocks.0.Batch...              [64]   \n",
      "109_conv_blocks_localization.4.1.blocks.0.Leaky...                 -   \n",
      "110_seg_outputs.Conv2d_4                               [64, 6, 1, 1]   \n",
      "111_tu.Upsample_5                                                  -   \n",
      "112_conv_blocks_localization.5.0.blocks.0.Conv2...   [128, 64, 3, 3]   \n",
      "113_conv_blocks_localization.5.0.blocks.0.Batch...              [64]   \n",
      "114_conv_blocks_localization.5.0.blocks.0.Leaky...                 -   \n",
      "115_conv_blocks_localization.5.1.blocks.0.Conv2...    [64, 32, 3, 3]   \n",
      "116_conv_blocks_localization.5.1.blocks.0.Batch...              [32]   \n",
      "117_conv_blocks_localization.5.1.blocks.0.Leaky...                 -   \n",
      "118_seg_outputs.Conv2d_5                               [32, 6, 1, 1]   \n",
      "119_tu.Upsample_6                                                  -   \n",
      "120_conv_blocks_localization.6.0.blocks.0.Conv2...    [64, 32, 3, 3]   \n",
      "121_conv_blocks_localization.6.0.blocks.0.Batch...              [32]   \n",
      "122_conv_blocks_localization.6.0.blocks.0.Leaky...                 -   \n",
      "123_conv_blocks_localization.6.1.blocks.0.Conv2...    [32, 32, 3, 3]   \n",
      "124_conv_blocks_localization.6.1.blocks.0.Batch...              [32]   \n",
      "125_conv_blocks_localization.6.1.blocks.0.Leaky...                 -   \n",
      "126_seg_outputs.Conv2d_6                               [32, 6, 1, 1]   \n",
      "\n",
      "                                                          Output Shape  \\\n",
      "Layer                                                                    \n",
      "0_conv_blocks_context.0.blocks.0.Conv2d_conv         [1, 32, 512, 512]   \n",
      "1_conv_blocks_context.0.blocks.0.Dropout2d_dropout   [1, 32, 512, 512]   \n",
      "2_conv_blocks_context.0.blocks.0.BatchNorm2d_in...   [1, 32, 512, 512]   \n",
      "3_conv_blocks_context.0.blocks.0.LeakyReLU_lrelu     [1, 32, 512, 512]   \n",
      "4_conv_blocks_context.0.blocks.1.Conv2d_conv         [1, 32, 512, 512]   \n",
      "5_conv_blocks_context.0.blocks.1.Dropout2d_dropout   [1, 32, 512, 512]   \n",
      "6_conv_blocks_context.0.blocks.1.BatchNorm2d_in...   [1, 32, 512, 512]   \n",
      "7_conv_blocks_context.0.blocks.1.LeakyReLU_lrelu     [1, 32, 512, 512]   \n",
      "8_td.MaxPool2d_0                                     [1, 32, 256, 256]   \n",
      "9_conv_blocks_context.1.blocks.0.Conv2d_conv         [1, 64, 256, 256]   \n",
      "10_conv_blocks_context.1.blocks.0.Dropout2d_dro...   [1, 64, 256, 256]   \n",
      "11_conv_blocks_context.1.blocks.0.BatchNorm2d_i...   [1, 64, 256, 256]   \n",
      "12_conv_blocks_context.1.blocks.0.LeakyReLU_lrelu    [1, 64, 256, 256]   \n",
      "13_conv_blocks_context.1.blocks.1.Conv2d_conv        [1, 64, 256, 256]   \n",
      "14_conv_blocks_context.1.blocks.1.Dropout2d_dro...   [1, 64, 256, 256]   \n",
      "15_conv_blocks_context.1.blocks.1.BatchNorm2d_i...   [1, 64, 256, 256]   \n",
      "16_conv_blocks_context.1.blocks.1.LeakyReLU_lrelu    [1, 64, 256, 256]   \n",
      "17_td.MaxPool2d_1                                    [1, 64, 128, 128]   \n",
      "18_conv_blocks_context.2.blocks.0.Conv2d_conv       [1, 128, 128, 128]   \n",
      "19_conv_blocks_context.2.blocks.0.Dropout2d_dro...  [1, 128, 128, 128]   \n",
      "20_conv_blocks_context.2.blocks.0.BatchNorm2d_i...  [1, 128, 128, 128]   \n",
      "21_conv_blocks_context.2.blocks.0.LeakyReLU_lrelu   [1, 128, 128, 128]   \n",
      "22_conv_blocks_context.2.blocks.1.Conv2d_conv       [1, 128, 128, 128]   \n",
      "23_conv_blocks_context.2.blocks.1.Dropout2d_dro...  [1, 128, 128, 128]   \n",
      "24_conv_blocks_context.2.blocks.1.BatchNorm2d_i...  [1, 128, 128, 128]   \n",
      "25_conv_blocks_context.2.blocks.1.LeakyReLU_lrelu   [1, 128, 128, 128]   \n",
      "26_td.MaxPool2d_2                                     [1, 128, 64, 64]   \n",
      "27_conv_blocks_context.3.blocks.0.Conv2d_conv         [1, 256, 64, 64]   \n",
      "28_conv_blocks_context.3.blocks.0.Dropout2d_dro...    [1, 256, 64, 64]   \n",
      "29_conv_blocks_context.3.blocks.0.BatchNorm2d_i...    [1, 256, 64, 64]   \n",
      "30_conv_blocks_context.3.blocks.0.LeakyReLU_lrelu     [1, 256, 64, 64]   \n",
      "31_conv_blocks_context.3.blocks.1.Conv2d_conv         [1, 256, 64, 64]   \n",
      "32_conv_blocks_context.3.blocks.1.Dropout2d_dro...    [1, 256, 64, 64]   \n",
      "33_conv_blocks_context.3.blocks.1.BatchNorm2d_i...    [1, 256, 64, 64]   \n",
      "34_conv_blocks_context.3.blocks.1.LeakyReLU_lrelu     [1, 256, 64, 64]   \n",
      "35_td.MaxPool2d_3                                     [1, 256, 32, 32]   \n",
      "36_conv_blocks_context.4.blocks.0.Conv2d_conv         [1, 480, 32, 32]   \n",
      "37_conv_blocks_context.4.blocks.0.Dropout2d_dro...    [1, 480, 32, 32]   \n",
      "38_conv_blocks_context.4.blocks.0.BatchNorm2d_i...    [1, 480, 32, 32]   \n",
      "39_conv_blocks_context.4.blocks.0.LeakyReLU_lrelu     [1, 480, 32, 32]   \n",
      "40_conv_blocks_context.4.blocks.1.Conv2d_conv         [1, 480, 32, 32]   \n",
      "41_conv_blocks_context.4.blocks.1.Dropout2d_dro...    [1, 480, 32, 32]   \n",
      "42_conv_blocks_context.4.blocks.1.BatchNorm2d_i...    [1, 480, 32, 32]   \n",
      "43_conv_blocks_context.4.blocks.1.LeakyReLU_lrelu     [1, 480, 32, 32]   \n",
      "44_td.MaxPool2d_4                                     [1, 480, 16, 16]   \n",
      "45_conv_blocks_context.5.blocks.0.Conv2d_conv         [1, 480, 16, 16]   \n",
      "46_conv_blocks_context.5.blocks.0.Dropout2d_dro...    [1, 480, 16, 16]   \n",
      "47_conv_blocks_context.5.blocks.0.BatchNorm2d_i...    [1, 480, 16, 16]   \n",
      "48_conv_blocks_context.5.blocks.0.LeakyReLU_lrelu     [1, 480, 16, 16]   \n",
      "49_conv_blocks_context.5.blocks.1.Conv2d_conv         [1, 480, 16, 16]   \n",
      "50_conv_blocks_context.5.blocks.1.Dropout2d_dro...    [1, 480, 16, 16]   \n",
      "51_conv_blocks_context.5.blocks.1.BatchNorm2d_i...    [1, 480, 16, 16]   \n",
      "52_conv_blocks_context.5.blocks.1.LeakyReLU_lrelu     [1, 480, 16, 16]   \n",
      "53_td.MaxPool2d_5                                       [1, 480, 8, 8]   \n",
      "54_conv_blocks_context.6.blocks.0.Conv2d_conv           [1, 480, 8, 8]   \n",
      "55_conv_blocks_context.6.blocks.0.Dropout2d_dro...      [1, 480, 8, 8]   \n",
      "56_conv_blocks_context.6.blocks.0.BatchNorm2d_i...      [1, 480, 8, 8]   \n",
      "57_conv_blocks_context.6.blocks.0.LeakyReLU_lrelu       [1, 480, 8, 8]   \n",
      "58_conv_blocks_context.6.blocks.1.Conv2d_conv           [1, 480, 8, 8]   \n",
      "59_conv_blocks_context.6.blocks.1.Dropout2d_dro...      [1, 480, 8, 8]   \n",
      "60_conv_blocks_context.6.blocks.1.BatchNorm2d_i...      [1, 480, 8, 8]   \n",
      "61_conv_blocks_context.6.blocks.1.LeakyReLU_lrelu       [1, 480, 8, 8]   \n",
      "62_td.MaxPool2d_6                                       [1, 480, 4, 4]   \n",
      "63_conv_blocks_context.7.0.blocks.0.Conv2d_conv         [1, 480, 4, 4]   \n",
      "64_conv_blocks_context.7.0.blocks.0.Dropout2d_d...      [1, 480, 4, 4]   \n",
      "65_conv_blocks_context.7.0.blocks.0.BatchNorm2d...      [1, 480, 4, 4]   \n",
      "66_conv_blocks_context.7.0.blocks.0.LeakyReLU_l...      [1, 480, 4, 4]   \n",
      "67_conv_blocks_context.7.1.blocks.0.Conv2d_conv         [1, 480, 4, 4]   \n",
      "68_conv_blocks_context.7.1.blocks.0.Dropout2d_d...      [1, 480, 4, 4]   \n",
      "69_conv_blocks_context.7.1.blocks.0.BatchNorm2d...      [1, 480, 4, 4]   \n",
      "70_conv_blocks_context.7.1.blocks.0.LeakyReLU_l...      [1, 480, 4, 4]   \n",
      "71_tu.Upsample_0                                        [1, 480, 8, 8]   \n",
      "72_conv_blocks_localization.0.0.blocks.0.Conv2d...      [1, 480, 8, 8]   \n",
      "73_conv_blocks_localization.0.0.blocks.0.BatchN...      [1, 480, 8, 8]   \n",
      "74_conv_blocks_localization.0.0.blocks.0.LeakyR...      [1, 480, 8, 8]   \n",
      "75_conv_blocks_localization.0.1.blocks.0.Conv2d...      [1, 480, 8, 8]   \n",
      "76_conv_blocks_localization.0.1.blocks.0.BatchN...      [1, 480, 8, 8]   \n",
      "77_conv_blocks_localization.0.1.blocks.0.LeakyR...      [1, 480, 8, 8]   \n",
      "78_seg_outputs.Conv2d_0                                   [1, 6, 8, 8]   \n",
      "79_tu.Upsample_1                                      [1, 480, 16, 16]   \n",
      "80_conv_blocks_localization.1.0.blocks.0.Conv2d...    [1, 480, 16, 16]   \n",
      "81_conv_blocks_localization.1.0.blocks.0.BatchN...    [1, 480, 16, 16]   \n",
      "82_conv_blocks_localization.1.0.blocks.0.LeakyR...    [1, 480, 16, 16]   \n",
      "83_conv_blocks_localization.1.1.blocks.0.Conv2d...    [1, 480, 16, 16]   \n",
      "84_conv_blocks_localization.1.1.blocks.0.BatchN...    [1, 480, 16, 16]   \n",
      "85_conv_blocks_localization.1.1.blocks.0.LeakyR...    [1, 480, 16, 16]   \n",
      "86_seg_outputs.Conv2d_1                                 [1, 6, 16, 16]   \n",
      "87_tu.Upsample_2                                      [1, 480, 32, 32]   \n",
      "88_conv_blocks_localization.2.0.blocks.0.Conv2d...    [1, 480, 32, 32]   \n",
      "89_conv_blocks_localization.2.0.blocks.0.BatchN...    [1, 480, 32, 32]   \n",
      "90_conv_blocks_localization.2.0.blocks.0.LeakyR...    [1, 480, 32, 32]   \n",
      "91_conv_blocks_localization.2.1.blocks.0.Conv2d...    [1, 256, 32, 32]   \n",
      "92_conv_blocks_localization.2.1.blocks.0.BatchN...    [1, 256, 32, 32]   \n",
      "93_conv_blocks_localization.2.1.blocks.0.LeakyR...    [1, 256, 32, 32]   \n",
      "94_seg_outputs.Conv2d_2                                 [1, 6, 32, 32]   \n",
      "95_tu.Upsample_3                                      [1, 256, 64, 64]   \n",
      "96_conv_blocks_localization.3.0.blocks.0.Conv2d...    [1, 256, 64, 64]   \n",
      "97_conv_blocks_localization.3.0.blocks.0.BatchN...    [1, 256, 64, 64]   \n",
      "98_conv_blocks_localization.3.0.blocks.0.LeakyR...    [1, 256, 64, 64]   \n",
      "99_conv_blocks_localization.3.1.blocks.0.Conv2d...    [1, 128, 64, 64]   \n",
      "100_conv_blocks_localization.3.1.blocks.0.Batch...    [1, 128, 64, 64]   \n",
      "101_conv_blocks_localization.3.1.blocks.0.Leaky...    [1, 128, 64, 64]   \n",
      "102_seg_outputs.Conv2d_3                                [1, 6, 64, 64]   \n",
      "103_tu.Upsample_4                                   [1, 128, 128, 128]   \n",
      "104_conv_blocks_localization.4.0.blocks.0.Conv2...  [1, 128, 128, 128]   \n",
      "105_conv_blocks_localization.4.0.blocks.0.Batch...  [1, 128, 128, 128]   \n",
      "106_conv_blocks_localization.4.0.blocks.0.Leaky...  [1, 128, 128, 128]   \n",
      "107_conv_blocks_localization.4.1.blocks.0.Conv2...   [1, 64, 128, 128]   \n",
      "108_conv_blocks_localization.4.1.blocks.0.Batch...   [1, 64, 128, 128]   \n",
      "109_conv_blocks_localization.4.1.blocks.0.Leaky...   [1, 64, 128, 128]   \n",
      "110_seg_outputs.Conv2d_4                              [1, 6, 128, 128]   \n",
      "111_tu.Upsample_5                                    [1, 64, 256, 256]   \n",
      "112_conv_blocks_localization.5.0.blocks.0.Conv2...   [1, 64, 256, 256]   \n",
      "113_conv_blocks_localization.5.0.blocks.0.Batch...   [1, 64, 256, 256]   \n",
      "114_conv_blocks_localization.5.0.blocks.0.Leaky...   [1, 64, 256, 256]   \n",
      "115_conv_blocks_localization.5.1.blocks.0.Conv2...   [1, 32, 256, 256]   \n",
      "116_conv_blocks_localization.5.1.blocks.0.Batch...   [1, 32, 256, 256]   \n",
      "117_conv_blocks_localization.5.1.blocks.0.Leaky...   [1, 32, 256, 256]   \n",
      "118_seg_outputs.Conv2d_5                              [1, 6, 256, 256]   \n",
      "119_tu.Upsample_6                                    [1, 32, 512, 512]   \n",
      "120_conv_blocks_localization.6.0.blocks.0.Conv2...   [1, 32, 512, 512]   \n",
      "121_conv_blocks_localization.6.0.blocks.0.Batch...   [1, 32, 512, 512]   \n",
      "122_conv_blocks_localization.6.0.blocks.0.Leaky...   [1, 32, 512, 512]   \n",
      "123_conv_blocks_localization.6.1.blocks.0.Conv2...   [1, 32, 512, 512]   \n",
      "124_conv_blocks_localization.6.1.blocks.0.Batch...   [1, 32, 512, 512]   \n",
      "125_conv_blocks_localization.6.1.blocks.0.Leaky...   [1, 32, 512, 512]   \n",
      "126_seg_outputs.Conv2d_6                              [1, 6, 512, 512]   \n",
      "\n",
      "                                                       Params     Mult-Adds  \n",
      "Layer                                                                        \n",
      "0_conv_blocks_context.0.blocks.0.Conv2d_conv            896.0   226.492416M  \n",
      "1_conv_blocks_context.0.blocks.0.Dropout2d_dropout          -             -  \n",
      "2_conv_blocks_context.0.blocks.0.BatchNorm2d_in...       64.0          32.0  \n",
      "3_conv_blocks_context.0.blocks.0.LeakyReLU_lrelu            -             -  \n",
      "4_conv_blocks_context.0.blocks.1.Conv2d_conv           9.248k  2.415919104G  \n",
      "5_conv_blocks_context.0.blocks.1.Dropout2d_dropout          -             -  \n",
      "6_conv_blocks_context.0.blocks.1.BatchNorm2d_in...       64.0          32.0  \n",
      "7_conv_blocks_context.0.blocks.1.LeakyReLU_lrelu            -             -  \n",
      "8_td.MaxPool2d_0                                            -             -  \n",
      "9_conv_blocks_context.1.blocks.0.Conv2d_conv          18.496k  1.207959552G  \n",
      "10_conv_blocks_context.1.blocks.0.Dropout2d_dro...          -             -  \n",
      "11_conv_blocks_context.1.blocks.0.BatchNorm2d_i...      128.0          64.0  \n",
      "12_conv_blocks_context.1.blocks.0.LeakyReLU_lrelu           -             -  \n",
      "13_conv_blocks_context.1.blocks.1.Conv2d_conv         36.928k  2.415919104G  \n",
      "14_conv_blocks_context.1.blocks.1.Dropout2d_dro...          -             -  \n",
      "15_conv_blocks_context.1.blocks.1.BatchNorm2d_i...      128.0          64.0  \n",
      "16_conv_blocks_context.1.blocks.1.LeakyReLU_lrelu           -             -  \n",
      "17_td.MaxPool2d_1                                           -             -  \n",
      "18_conv_blocks_context.2.blocks.0.Conv2d_conv         73.856k  1.207959552G  \n",
      "19_conv_blocks_context.2.blocks.0.Dropout2d_dro...          -             -  \n",
      "20_conv_blocks_context.2.blocks.0.BatchNorm2d_i...      256.0         128.0  \n",
      "21_conv_blocks_context.2.blocks.0.LeakyReLU_lrelu           -             -  \n",
      "22_conv_blocks_context.2.blocks.1.Conv2d_conv        147.584k  2.415919104G  \n",
      "23_conv_blocks_context.2.blocks.1.Dropout2d_dro...          -             -  \n",
      "24_conv_blocks_context.2.blocks.1.BatchNorm2d_i...      256.0         128.0  \n",
      "25_conv_blocks_context.2.blocks.1.LeakyReLU_lrelu           -             -  \n",
      "26_td.MaxPool2d_2                                           -             -  \n",
      "27_conv_blocks_context.3.blocks.0.Conv2d_conv        295.168k  1.207959552G  \n",
      "28_conv_blocks_context.3.blocks.0.Dropout2d_dro...          -             -  \n",
      "29_conv_blocks_context.3.blocks.0.BatchNorm2d_i...      512.0         256.0  \n",
      "30_conv_blocks_context.3.blocks.0.LeakyReLU_lrelu           -             -  \n",
      "31_conv_blocks_context.3.blocks.1.Conv2d_conv         590.08k  2.415919104G  \n",
      "32_conv_blocks_context.3.blocks.1.Dropout2d_dro...          -             -  \n",
      "33_conv_blocks_context.3.blocks.1.BatchNorm2d_i...      512.0         256.0  \n",
      "34_conv_blocks_context.3.blocks.1.LeakyReLU_lrelu           -             -  \n",
      "35_td.MaxPool2d_3                                           -             -  \n",
      "36_conv_blocks_context.4.blocks.0.Conv2d_conv         1.1064M   1.13246208G  \n",
      "37_conv_blocks_context.4.blocks.0.Dropout2d_dro...          -             -  \n",
      "38_conv_blocks_context.4.blocks.0.BatchNorm2d_i...      960.0         480.0  \n",
      "39_conv_blocks_context.4.blocks.0.LeakyReLU_lrelu           -             -  \n",
      "40_conv_blocks_context.4.blocks.1.Conv2d_conv        2.07408M    2.1233664G  \n",
      "41_conv_blocks_context.4.blocks.1.Dropout2d_dro...          -             -  \n",
      "42_conv_blocks_context.4.blocks.1.BatchNorm2d_i...      960.0         480.0  \n",
      "43_conv_blocks_context.4.blocks.1.LeakyReLU_lrelu           -             -  \n",
      "44_td.MaxPool2d_4                                           -             -  \n",
      "45_conv_blocks_context.5.blocks.0.Conv2d_conv        2.07408M     530.8416M  \n",
      "46_conv_blocks_context.5.blocks.0.Dropout2d_dro...          -             -  \n",
      "47_conv_blocks_context.5.blocks.0.BatchNorm2d_i...      960.0         480.0  \n",
      "48_conv_blocks_context.5.blocks.0.LeakyReLU_lrelu           -             -  \n",
      "49_conv_blocks_context.5.blocks.1.Conv2d_conv        2.07408M     530.8416M  \n",
      "50_conv_blocks_context.5.blocks.1.Dropout2d_dro...          -             -  \n",
      "51_conv_blocks_context.5.blocks.1.BatchNorm2d_i...      960.0         480.0  \n",
      "52_conv_blocks_context.5.blocks.1.LeakyReLU_lrelu           -             -  \n",
      "53_td.MaxPool2d_5                                           -             -  \n",
      "54_conv_blocks_context.6.blocks.0.Conv2d_conv        2.07408M     132.7104M  \n",
      "55_conv_blocks_context.6.blocks.0.Dropout2d_dro...          -             -  \n",
      "56_conv_blocks_context.6.blocks.0.BatchNorm2d_i...      960.0         480.0  \n",
      "57_conv_blocks_context.6.blocks.0.LeakyReLU_lrelu           -             -  \n",
      "58_conv_blocks_context.6.blocks.1.Conv2d_conv        2.07408M     132.7104M  \n",
      "59_conv_blocks_context.6.blocks.1.Dropout2d_dro...          -             -  \n",
      "60_conv_blocks_context.6.blocks.1.BatchNorm2d_i...      960.0         480.0  \n",
      "61_conv_blocks_context.6.blocks.1.LeakyReLU_lrelu           -             -  \n",
      "62_td.MaxPool2d_6                                           -             -  \n",
      "63_conv_blocks_context.7.0.blocks.0.Conv2d_conv      2.07408M      33.1776M  \n",
      "64_conv_blocks_context.7.0.blocks.0.Dropout2d_d...          -             -  \n",
      "65_conv_blocks_context.7.0.blocks.0.BatchNorm2d...      960.0         480.0  \n",
      "66_conv_blocks_context.7.0.blocks.0.LeakyReLU_l...          -             -  \n",
      "67_conv_blocks_context.7.1.blocks.0.Conv2d_conv      2.07408M      33.1776M  \n",
      "68_conv_blocks_context.7.1.blocks.0.Dropout2d_d...          -             -  \n",
      "69_conv_blocks_context.7.1.blocks.0.BatchNorm2d...      960.0         480.0  \n",
      "70_conv_blocks_context.7.1.blocks.0.LeakyReLU_l...          -             -  \n",
      "71_tu.Upsample_0                                            -             -  \n",
      "72_conv_blocks_localization.0.0.blocks.0.Conv2d...   4.14768M     265.4208M  \n",
      "73_conv_blocks_localization.0.0.blocks.0.BatchN...      960.0         480.0  \n",
      "74_conv_blocks_localization.0.0.blocks.0.LeakyR...          -             -  \n",
      "75_conv_blocks_localization.0.1.blocks.0.Conv2d...   2.07408M     132.7104M  \n",
      "76_conv_blocks_localization.0.1.blocks.0.BatchN...      960.0         480.0  \n",
      "77_conv_blocks_localization.0.1.blocks.0.LeakyR...          -             -  \n",
      "78_seg_outputs.Conv2d_0                                 2.88k       184.32k  \n",
      "79_tu.Upsample_1                                            -             -  \n",
      "80_conv_blocks_localization.1.0.blocks.0.Conv2d...   4.14768M    1.0616832G  \n",
      "81_conv_blocks_localization.1.0.blocks.0.BatchN...      960.0         480.0  \n",
      "82_conv_blocks_localization.1.0.blocks.0.LeakyR...          -             -  \n",
      "83_conv_blocks_localization.1.1.blocks.0.Conv2d...   2.07408M     530.8416M  \n",
      "84_conv_blocks_localization.1.1.blocks.0.BatchN...      960.0         480.0  \n",
      "85_conv_blocks_localization.1.1.blocks.0.LeakyR...          -             -  \n",
      "86_seg_outputs.Conv2d_1                                 2.88k       737.28k  \n",
      "87_tu.Upsample_2                                            -             -  \n",
      "88_conv_blocks_localization.2.0.blocks.0.Conv2d...   4.14768M    4.2467328G  \n",
      "89_conv_blocks_localization.2.0.blocks.0.BatchN...      960.0         480.0  \n",
      "90_conv_blocks_localization.2.0.blocks.0.LeakyR...          -             -  \n",
      "91_conv_blocks_localization.2.1.blocks.0.Conv2d...  1.106176M   1.13246208G  \n",
      "92_conv_blocks_localization.2.1.blocks.0.BatchN...      512.0         256.0  \n",
      "93_conv_blocks_localization.2.1.blocks.0.LeakyR...          -             -  \n",
      "94_seg_outputs.Conv2d_2                                1.536k     1.572864M  \n",
      "95_tu.Upsample_3                                            -             -  \n",
      "96_conv_blocks_localization.3.0.blocks.0.Conv2d...  1.179904M  4.831838208G  \n",
      "97_conv_blocks_localization.3.0.blocks.0.BatchN...      512.0         256.0  \n",
      "98_conv_blocks_localization.3.0.blocks.0.LeakyR...          -             -  \n",
      "99_conv_blocks_localization.3.1.blocks.0.Conv2d...    295.04k  1.207959552G  \n",
      "100_conv_blocks_localization.3.1.blocks.0.Batch...      256.0         128.0  \n",
      "101_conv_blocks_localization.3.1.blocks.0.Leaky...          -             -  \n",
      "102_seg_outputs.Conv2d_3                                768.0     3.145728M  \n",
      "103_tu.Upsample_4                                           -             -  \n",
      "104_conv_blocks_localization.4.0.blocks.0.Conv2...    295.04k  4.831838208G  \n",
      "105_conv_blocks_localization.4.0.blocks.0.Batch...      256.0         128.0  \n",
      "106_conv_blocks_localization.4.0.blocks.0.Leaky...          -             -  \n",
      "107_conv_blocks_localization.4.1.blocks.0.Conv2...    73.792k  1.207959552G  \n",
      "108_conv_blocks_localization.4.1.blocks.0.Batch...      128.0          64.0  \n",
      "109_conv_blocks_localization.4.1.blocks.0.Leaky...          -             -  \n",
      "110_seg_outputs.Conv2d_4                                384.0     6.291456M  \n",
      "111_tu.Upsample_5                                           -             -  \n",
      "112_conv_blocks_localization.5.0.blocks.0.Conv2...    73.792k  4.831838208G  \n",
      "113_conv_blocks_localization.5.0.blocks.0.Batch...      128.0          64.0  \n",
      "114_conv_blocks_localization.5.0.blocks.0.Leaky...          -             -  \n",
      "115_conv_blocks_localization.5.1.blocks.0.Conv2...    18.464k  1.207959552G  \n",
      "116_conv_blocks_localization.5.1.blocks.0.Batch...       64.0          32.0  \n",
      "117_conv_blocks_localization.5.1.blocks.0.Leaky...          -             -  \n",
      "118_seg_outputs.Conv2d_5                                192.0    12.582912M  \n",
      "119_tu.Upsample_6                                           -             -  \n",
      "120_conv_blocks_localization.6.0.blocks.0.Conv2...    18.464k  4.831838208G  \n",
      "121_conv_blocks_localization.6.0.blocks.0.Batch...       64.0          32.0  \n",
      "122_conv_blocks_localization.6.0.blocks.0.Leaky...          -             -  \n",
      "123_conv_blocks_localization.6.1.blocks.0.Conv2...     9.248k  2.415919104G  \n",
      "124_conv_blocks_localization.6.1.blocks.0.Batch...       64.0          32.0  \n",
      "125_conv_blocks_localization.6.1.blocks.0.Leaky...          -             -  \n",
      "126_seg_outputs.Conv2d_6                                192.0    50.331648M  \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params            36.483552M\n",
      "Trainable params        36.483552M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             50.97519104G\n",
      "=============================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_conv_blocks_context.0.blocks.0.Conv2d_conv</th>\n",
       "      <td>[3, 32, 3, 3]</td>\n",
       "      <td>[1, 32, 512, 512]</td>\n",
       "      <td>896.0</td>\n",
       "      <td>2.264924e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_conv_blocks_context.0.blocks.0.Dropout2d_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 32, 512, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_conv_blocks_context.0.blocks.0.BatchNorm2d_instnorm</th>\n",
       "      <td>[32]</td>\n",
       "      <td>[1, 32, 512, 512]</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_conv_blocks_context.0.blocks.0.LeakyReLU_lrelu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 32, 512, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_conv_blocks_context.0.blocks.1.Conv2d_conv</th>\n",
       "      <td>[32, 32, 3, 3]</td>\n",
       "      <td>[1, 32, 512, 512]</td>\n",
       "      <td>9248.0</td>\n",
       "      <td>2.415919e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122_conv_blocks_localization.6.0.blocks.0.LeakyReLU_lrelu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 32, 512, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123_conv_blocks_localization.6.1.blocks.0.Conv2d_conv</th>\n",
       "      <td>[32, 32, 3, 3]</td>\n",
       "      <td>[1, 32, 512, 512]</td>\n",
       "      <td>9248.0</td>\n",
       "      <td>2.415919e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124_conv_blocks_localization.6.1.blocks.0.BatchNorm2d_instnorm</th>\n",
       "      <td>[32]</td>\n",
       "      <td>[1, 32, 512, 512]</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125_conv_blocks_localization.6.1.blocks.0.LeakyReLU_lrelu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 32, 512, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126_seg_outputs.Conv2d_6</th>\n",
       "      <td>[32, 6, 1, 1]</td>\n",
       "      <td>[1, 6, 512, 512]</td>\n",
       "      <td>192.0</td>\n",
       "      <td>5.033165e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Kernel Shape  \\\n",
       "Layer                                                                \n",
       "0_conv_blocks_context.0.blocks.0.Conv2d_conv         [3, 32, 3, 3]   \n",
       "1_conv_blocks_context.0.blocks.0.Dropout2d_dropout               -   \n",
       "2_conv_blocks_context.0.blocks.0.BatchNorm2d_in...            [32]   \n",
       "3_conv_blocks_context.0.blocks.0.LeakyReLU_lrelu                 -   \n",
       "4_conv_blocks_context.0.blocks.1.Conv2d_conv        [32, 32, 3, 3]   \n",
       "...                                                            ...   \n",
       "122_conv_blocks_localization.6.0.blocks.0.Leaky...               -   \n",
       "123_conv_blocks_localization.6.1.blocks.0.Conv2...  [32, 32, 3, 3]   \n",
       "124_conv_blocks_localization.6.1.blocks.0.Batch...            [32]   \n",
       "125_conv_blocks_localization.6.1.blocks.0.Leaky...               -   \n",
       "126_seg_outputs.Conv2d_6                             [32, 6, 1, 1]   \n",
       "\n",
       "                                                         Output Shape  Params  \\\n",
       "Layer                                                                           \n",
       "0_conv_blocks_context.0.blocks.0.Conv2d_conv        [1, 32, 512, 512]   896.0   \n",
       "1_conv_blocks_context.0.blocks.0.Dropout2d_dropout  [1, 32, 512, 512]     NaN   \n",
       "2_conv_blocks_context.0.blocks.0.BatchNorm2d_in...  [1, 32, 512, 512]    64.0   \n",
       "3_conv_blocks_context.0.blocks.0.LeakyReLU_lrelu    [1, 32, 512, 512]     NaN   \n",
       "4_conv_blocks_context.0.blocks.1.Conv2d_conv        [1, 32, 512, 512]  9248.0   \n",
       "...                                                               ...     ...   \n",
       "122_conv_blocks_localization.6.0.blocks.0.Leaky...  [1, 32, 512, 512]     NaN   \n",
       "123_conv_blocks_localization.6.1.blocks.0.Conv2...  [1, 32, 512, 512]  9248.0   \n",
       "124_conv_blocks_localization.6.1.blocks.0.Batch...  [1, 32, 512, 512]    64.0   \n",
       "125_conv_blocks_localization.6.1.blocks.0.Leaky...  [1, 32, 512, 512]     NaN   \n",
       "126_seg_outputs.Conv2d_6                             [1, 6, 512, 512]   192.0   \n",
       "\n",
       "                                                       Mult-Adds  \n",
       "Layer                                                             \n",
       "0_conv_blocks_context.0.blocks.0.Conv2d_conv        2.264924e+08  \n",
       "1_conv_blocks_context.0.blocks.0.Dropout2d_dropout           NaN  \n",
       "2_conv_blocks_context.0.blocks.0.BatchNorm2d_in...  3.200000e+01  \n",
       "3_conv_blocks_context.0.blocks.0.LeakyReLU_lrelu             NaN  \n",
       "4_conv_blocks_context.0.blocks.1.Conv2d_conv        2.415919e+09  \n",
       "...                                                          ...  \n",
       "122_conv_blocks_localization.6.0.blocks.0.Leaky...           NaN  \n",
       "123_conv_blocks_localization.6.1.blocks.0.Conv2...  2.415919e+09  \n",
       "124_conv_blocks_localization.6.1.blocks.0.Batch...  3.200000e+01  \n",
       "125_conv_blocks_localization.6.1.blocks.0.Leaky...           NaN  \n",
       "126_seg_outputs.Conv2d_6                            5.033165e+07  \n",
       "\n",
       "[127 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(nnunet, torch.zeros((1, 3, 512, 512), device=\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49b71adf-acc8-4f98-8544-b20265848a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339233792"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6131c62f-b7a1-4812-b6db-3930675f001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493491200.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91110a0d-b0de-4136-a7e4-9e7e92e5baeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "here > ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06e46d65-786e-45fd-8759-cc6c2aee45f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "[#] Found plans and preprocessed data for Task501_endometrium_carcinoma_segmentation - copying to compute node\n",
      "[#] Found plans and preprocessed data for Task501_endometrium_carcinoma_segmentation - copied to compute node\n",
      "[#] Resuming network training\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEandDice_Weighted.nnUNetTrainer_V2_Loss_CEandDice_Weighted'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  7\n",
      "modalities:  {0: 'R Histopathology', 1: 'G Histopathology', 2: 'B Histopathology'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False), (2, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT'), (1, 'nonCT'), (2, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [8, 8], 'patch_size': array([1024, 1280]), 'median_patient_size_in_voxels': array([   1, 1024, 1066]), 'current_spacing': array([999.,   1.,   1.]), 'original_spacing': array([999.,   1.,   1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /home/user/data/Task501_endometrium_carcinoma_segmentation/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "{'class_weights': [0, 115, 93, 148, 73, 35, 18, 482],\n",
      " 'ignore_label': 0,\n",
      " 'weight_ce': 0.3,\n",
      " 'weight_dc': 0.7}\n",
      "Using DCandCEWeightedLoss with the following parameters:\n",
      " None\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2022-08-25 15:55:03.009312: Using splits from existing split file: /home/user/data/Task501_endometrium_carcinoma_segmentation/splits_final.pkl\n",
      "2022-08-25 15:55:03.028394: The split file contains 4 splits.\n",
      "2022-08-25 15:55:03.029354: Desired fold for training: 1\n",
      "2022-08-25 15:55:03.030247: This split has 308 training and 102 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2022-08-25 15:55:04.462969: loading checkpoint /data/pathology/projects/pathology-endoaid/phase 3 - nnUNet/nnUNet_raw_data_base_7cl_revised/results_VRAM_inspection/nnUNet/2d/Task501_endometrium_carcinoma_segmentation/nnUNetTrainer_V2_Loss_CEandDice_Weighted__nnUNetPlansv2.1/fold_1/model_best.model train= True\n",
      "2022-08-25 15:55:05.526457: lr: 0.009964\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2022-08-25 15:55:20.785569: \n",
      "epoch:  4\n",
      "2022-08-25 15:58:38.625592: train loss : 0.1972\n",
      "2022-08-25 15:58:52.778006: validation loss: 0.3669\n",
      "2022-08-25 15:58:52.783510: Average global foreground Dice: [0.1481, 0.1271, 0.0683, 0.4087, 0.5523, 0.7135, 0.0]\n",
      "2022-08-25 15:58:52.784463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-08-25 15:58:53.768315: lr: 0.009955\n",
      "2022-08-25 15:58:53.906302: saving checkpoint...\n",
      "2022-08-25 15:58:55.267454: done, saving took 1.50 seconds\n",
      "2022-08-25 15:58:55.313921: This epoch took 214.525116 s\n",
      "\n",
      "2022-08-25 15:58:55.315647: \n",
      "epoch:  5\n",
      "2022-08-25 16:02:06.755058: train loss : 0.1811\n",
      "2022-08-25 16:02:20.371783: validation loss: 0.3864\n",
      "2022-08-25 16:02:20.377655: Average global foreground Dice: [0.1186, 0.0055, 0.0336, 0.3932, 0.5082, 0.7349, 0.0]\n",
      "2022-08-25 16:02:20.378723: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-08-25 16:02:21.184124: lr: 0.009946\n",
      "2022-08-25 16:02:21.185661: This epoch took 205.868692 s\n",
      "\n",
      "2022-08-25 16:02:21.186709: \n",
      "epoch:  6\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.9/site-packages/nnunet/run/run_training.py\", line 185, in main\n",
      "    trainer.run_training()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/nnunet/training/network_training/nnUNetTrainerV2.py\", line 440, in run_training\n",
      "    ret = super().run_training()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/nnunet/training/network_training/nnUNetTrainer.py\", line 315, in run_training\n",
      "    super(nnUNetTrainer, self).run_training()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/nnunet/training/network_training/network_trainer.py\", line 456, in run_training\n",
      "    l = self.run_iteration(self.tr_gen, True)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/nnunet/training/network_training/nnUNetTrainerV2.py\", line 254, in run_iteration\n",
      "    torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/torch/nn/utils/clip_grad.py\", line 42, in clip_grad_norm_\n",
      "    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/torch/nn/utils/clip_grad.py\", line 42, in <listcomp>\n",
      "    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/torch/functional.py\", line 1421, in norm\n",
      "    return _VF.norm(input, p, dim=_dim, keepdim=keepdim)  # type: ignore[attr-defined]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!nnunet plan_train Task501_endometrium_carcinoma_segmentation \"/data/pathology/projects/pathology-endoaid/phase 3 - nnUNet/nnUNet_raw_data_base_7cl_revised\" --fold 1 --trainer nnUNetTrainer_V2_Loss_CEandDice_Weighted --results \"/data/pathology/projects/pathology-endoaid/phase 3 - nnUNet/nnUNet_raw_data_base_7cl_revised/results_VRAM_inspection\" --dont_plan_3d --plan_2d --network 2d --trainer_kwargs='{\\\"ignore_label\\\":0,\\\"class_weights\\\":[0,115,93,148,73,35,18,482],\\\"weight_dc\\\":0.7,\\\"weight_ce\\\":0.3}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
